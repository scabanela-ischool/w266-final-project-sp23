{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bdb15e45",
   "metadata": {},
   "source": [
    "# Data Preparation\n",
    "Data source: https://www.kaggle.com/competitions/jigsaw-unintended-bias-in-toxicity-classification/data?select=all_data.csv\n",
    "\n",
    "In this notebook, we prepare the data downloaded from kaggle and export data subsets which we will feed into our models. The data preparation process includes data cleaning, extracting data subsets according to identity category, and splitting each identity subset into train, validation, and test sets via stratified sampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ef6f6faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1d04d83",
   "metadata": {},
   "source": [
    "## Load the data:\n",
    "The kaggle competition corresponding to this dataset came with csv files for their own train and test subset. However, since the competition has ended, the `all_data.csv` file was released containing labels for both the train and test sets. Therefore, we'll be using the `all_data.csv` as our starting dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6108c6fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data_df = pd.read_csv('data/all_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c238e94",
   "metadata": {},
   "source": [
    "## Clean the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35d13e1f",
   "metadata": {},
   "source": [
    "EDA revealed that there were some rows with a missing value for `comment_text`. What does these rows look like?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7ca35dde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>split</th>\n",
       "      <th>created_date</th>\n",
       "      <th>publication_id</th>\n",
       "      <th>parent_id</th>\n",
       "      <th>article_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>funny</th>\n",
       "      <th>wow</th>\n",
       "      <th>...</th>\n",
       "      <th>white</th>\n",
       "      <th>asian</th>\n",
       "      <th>latino</th>\n",
       "      <th>other_race_or_ethnicity</th>\n",
       "      <th>physical_disability</th>\n",
       "      <th>intellectual_or_learning_disability</th>\n",
       "      <th>psychiatric_or_mental_illness</th>\n",
       "      <th>other_disability</th>\n",
       "      <th>identity_annotator_count</th>\n",
       "      <th>toxicity_annotator_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>446630</th>\n",
       "      <td>392337</td>\n",
       "      <td>NaN</td>\n",
       "      <td>train</td>\n",
       "      <td>2016-07-18 19:34:48.278774+00</td>\n",
       "      <td>13</td>\n",
       "      <td>392165.0</td>\n",
       "      <td>141670</td>\n",
       "      <td>approved</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>869804</th>\n",
       "      <td>872115</td>\n",
       "      <td>NaN</td>\n",
       "      <td>train</td>\n",
       "      <td>2017-01-21 02:04:30.064452+00</td>\n",
       "      <td>54</td>\n",
       "      <td>872109.0</td>\n",
       "      <td>163140</td>\n",
       "      <td>approved</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1556982</th>\n",
       "      <td>5971919</td>\n",
       "      <td>NaN</td>\n",
       "      <td>train</td>\n",
       "      <td>2017-09-18 02:40:48.161601+00</td>\n",
       "      <td>13</td>\n",
       "      <td>5971615.0</td>\n",
       "      <td>378393</td>\n",
       "      <td>approved</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1567442</th>\n",
       "      <td>5353666</td>\n",
       "      <td>NaN</td>\n",
       "      <td>train</td>\n",
       "      <td>2017-06-04 02:48:07.950238+00</td>\n",
       "      <td>13</td>\n",
       "      <td>5352881.0</td>\n",
       "      <td>340316</td>\n",
       "      <td>approved</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 46 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              id comment_text  split                   created_date   \n",
       "446630    392337          NaN  train  2016-07-18 19:34:48.278774+00  \\\n",
       "869804    872115          NaN  train  2017-01-21 02:04:30.064452+00   \n",
       "1556982  5971919          NaN  train  2017-09-18 02:40:48.161601+00   \n",
       "1567442  5353666          NaN  train  2017-06-04 02:48:07.950238+00   \n",
       "\n",
       "         publication_id  parent_id  article_id    rating  funny  wow  ...   \n",
       "446630               13   392165.0      141670  approved      0    0  ...  \\\n",
       "869804               54   872109.0      163140  approved      5    0  ...   \n",
       "1556982              13  5971615.0      378393  approved      0    0  ...   \n",
       "1567442              13  5352881.0      340316  approved      0    0  ...   \n",
       "\n",
       "         white  asian  latino  other_race_or_ethnicity  physical_disability   \n",
       "446630     NaN    NaN     NaN                      NaN                  NaN  \\\n",
       "869804     NaN    NaN     NaN                      NaN                  NaN   \n",
       "1556982    0.0    0.0     0.0                      0.0                  0.0   \n",
       "1567442    0.0    0.0     0.0                      0.0                  0.0   \n",
       "\n",
       "         intellectual_or_learning_disability  psychiatric_or_mental_illness   \n",
       "446630                                   NaN                            NaN  \\\n",
       "869804                                   NaN                            NaN   \n",
       "1556982                                  0.0                            0.0   \n",
       "1567442                                  0.0                            0.0   \n",
       "\n",
       "         other_disability  identity_annotator_count  toxicity_annotator_count  \n",
       "446630                NaN                         0                         4  \n",
       "869804                NaN                         0                         4  \n",
       "1556982               0.0                         4                         4  \n",
       "1567442               0.0                         4                         4  \n",
       "\n",
       "[4 rows x 46 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data_df[pd.isna(all_data_df[\"comment_text\"])]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa74e4d9",
   "metadata": {},
   "source": [
    "### Delete the rows with missing comments\n",
    "Since we'll have no input text to feed in for these rows, it will be unusable and therefore we'll remove them from our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "08e9a6f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data_df_cleansed = all_data_df.copy().drop(index=all_data_df[pd.isna(all_data_df['comment_text'])].index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41494a9d",
   "metadata": {},
   "source": [
    "We can see that we now have a few less lines in our dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "010e104e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1999516, 46)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8482b9de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1999512, 46)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data_df_cleansed.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02e3d264",
   "metadata": {},
   "source": [
    "## Basic feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4287fb39",
   "metadata": {},
   "source": [
    "### Add `toxicity_binary` column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5d2a7926",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data_df_cleansed['toxicity_binary'] = (all_data_df_cleansed['toxicity'] >= 0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3f9a069b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>toxicity</th>\n",
       "      <th>toxicity_binary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.373134</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.605263</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.666667</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.815789</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.550000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999511</th>\n",
       "      <td>0.400000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999512</th>\n",
       "      <td>0.400000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999513</th>\n",
       "      <td>0.400000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999514</th>\n",
       "      <td>0.400000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999515</th>\n",
       "      <td>0.400000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1999512 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         toxicity  toxicity_binary\n",
       "0        0.373134                0\n",
       "1        0.605263                1\n",
       "2        0.666667                1\n",
       "3        0.815789                1\n",
       "4        0.550000                1\n",
       "...           ...              ...\n",
       "1999511  0.400000                0\n",
       "1999512  0.400000                0\n",
       "1999513  0.400000                0\n",
       "1999514  0.400000                0\n",
       "1999515  0.400000                0\n",
       "\n",
       "[1999512 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data_df_cleansed[['toxicity','toxicity_binary']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cc32ac5",
   "metadata": {},
   "source": [
    "Move the new column towards the front of the dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7dff6f57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxicity_binary</th>\n",
       "      <th>split</th>\n",
       "      <th>created_date</th>\n",
       "      <th>publication_id</th>\n",
       "      <th>parent_id</th>\n",
       "      <th>article_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>funny</th>\n",
       "      <th>...</th>\n",
       "      <th>white</th>\n",
       "      <th>asian</th>\n",
       "      <th>latino</th>\n",
       "      <th>other_race_or_ethnicity</th>\n",
       "      <th>physical_disability</th>\n",
       "      <th>intellectual_or_learning_disability</th>\n",
       "      <th>psychiatric_or_mental_illness</th>\n",
       "      <th>other_disability</th>\n",
       "      <th>identity_annotator_count</th>\n",
       "      <th>toxicity_annotator_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1083994</td>\n",
       "      <td>He got his money... now he lies in wait till a...</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "      <td>2017-03-06 15:21:53.675241+00</td>\n",
       "      <td>21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>317120</td>\n",
       "      <td>approved</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>650904</td>\n",
       "      <td>Mad dog will surely put the liberals in mental...</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "      <td>2016-12-02 16:44:21.329535+00</td>\n",
       "      <td>21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>154086</td>\n",
       "      <td>approved</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5902188</td>\n",
       "      <td>And Trump continues his lifelong cowardice by ...</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "      <td>2017-09-05 19:05:32.341360+00</td>\n",
       "      <td>55</td>\n",
       "      <td>NaN</td>\n",
       "      <td>374342</td>\n",
       "      <td>approved</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7084460</td>\n",
       "      <td>\"while arresting a man for resisting arrest\".\\...</td>\n",
       "      <td>1</td>\n",
       "      <td>test</td>\n",
       "      <td>2016-11-01 16:53:33.561631+00</td>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>149218</td>\n",
       "      <td>approved</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5410943</td>\n",
       "      <td>Tucker and Paul are both total bad ass mofo's.</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "      <td>2017-06-14 05:08:21.997315+00</td>\n",
       "      <td>21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>344096</td>\n",
       "      <td>approved</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 47 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                       comment_text   \n",
       "0  1083994  He got his money... now he lies in wait till a...  \\\n",
       "1   650904  Mad dog will surely put the liberals in mental...   \n",
       "2  5902188  And Trump continues his lifelong cowardice by ...   \n",
       "3  7084460  \"while arresting a man for resisting arrest\".\\...   \n",
       "4  5410943     Tucker and Paul are both total bad ass mofo's.   \n",
       "\n",
       "   toxicity_binary  split                   created_date  publication_id   \n",
       "0                0  train  2017-03-06 15:21:53.675241+00              21  \\\n",
       "1                1  train  2016-12-02 16:44:21.329535+00              21   \n",
       "2                1  train  2017-09-05 19:05:32.341360+00              55   \n",
       "3                1   test  2016-11-01 16:53:33.561631+00              13   \n",
       "4                1  train  2017-06-14 05:08:21.997315+00              21   \n",
       "\n",
       "   parent_id  article_id    rating  funny  ...  white  asian  latino   \n",
       "0        NaN      317120  approved      0  ...    NaN    NaN     NaN  \\\n",
       "1        NaN      154086  approved      0  ...    NaN    NaN     NaN   \n",
       "2        NaN      374342  approved      1  ...    NaN    NaN     NaN   \n",
       "3        NaN      149218  approved      0  ...    NaN    NaN     NaN   \n",
       "4        NaN      344096  approved      0  ...    NaN    NaN     NaN   \n",
       "\n",
       "   other_race_or_ethnicity  physical_disability   \n",
       "0                      NaN                  NaN  \\\n",
       "1                      NaN                  NaN   \n",
       "2                      NaN                  NaN   \n",
       "3                      NaN                  NaN   \n",
       "4                      NaN                  NaN   \n",
       "\n",
       "   intellectual_or_learning_disability  psychiatric_or_mental_illness   \n",
       "0                                  NaN                            NaN  \\\n",
       "1                                  NaN                            NaN   \n",
       "2                                  NaN                            NaN   \n",
       "3                                  NaN                            NaN   \n",
       "4                                  NaN                            NaN   \n",
       "\n",
       "   other_disability  identity_annotator_count  toxicity_annotator_count  \n",
       "0               NaN                         0                        67  \n",
       "1               NaN                         0                        76  \n",
       "2               NaN                         0                        63  \n",
       "3               NaN                         0                        76  \n",
       "4               NaN                         0                        80  \n",
       "\n",
       "[5 rows x 47 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orig_cols = all_data_df_cleansed.columns.tolist()\n",
    "reordered_cols = orig_cols[:2] + orig_cols[-1:] + orig_cols[2:-1]\n",
    "all_data_df_cleansed = all_data_df_cleansed[reordered_cols]\n",
    "all_data_df_cleansed.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faeb98e1",
   "metadata": {},
   "source": [
    "## Drop the columns we won't be using"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2ff8c97f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxicity_binary</th>\n",
       "      <th>toxicity</th>\n",
       "      <th>male</th>\n",
       "      <th>female</th>\n",
       "      <th>transgender</th>\n",
       "      <th>other_gender</th>\n",
       "      <th>heterosexual</th>\n",
       "      <th>homosexual_gay_or_lesbian</th>\n",
       "      <th>bisexual</th>\n",
       "      <th>...</th>\n",
       "      <th>other_religion</th>\n",
       "      <th>black</th>\n",
       "      <th>white</th>\n",
       "      <th>asian</th>\n",
       "      <th>latino</th>\n",
       "      <th>other_race_or_ethnicity</th>\n",
       "      <th>physical_disability</th>\n",
       "      <th>intellectual_or_learning_disability</th>\n",
       "      <th>psychiatric_or_mental_illness</th>\n",
       "      <th>other_disability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>He got his money... now he lies in wait till a...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.373134</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mad dog will surely put the liberals in mental...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.605263</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>And Trump continues his lifelong cowardice by ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"while arresting a man for resisting arrest\".\\...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.815789</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Tucker and Paul are both total bad ass mofo's.</td>\n",
       "      <td>1</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        comment_text  toxicity_binary   \n",
       "0  He got his money... now he lies in wait till a...                0  \\\n",
       "1  Mad dog will surely put the liberals in mental...                1   \n",
       "2  And Trump continues his lifelong cowardice by ...                1   \n",
       "3  \"while arresting a man for resisting arrest\".\\...                1   \n",
       "4     Tucker and Paul are both total bad ass mofo's.                1   \n",
       "\n",
       "   toxicity  male  female  transgender  other_gender  heterosexual   \n",
       "0  0.373134   NaN     NaN          NaN           NaN           NaN  \\\n",
       "1  0.605263   NaN     NaN          NaN           NaN           NaN   \n",
       "2  0.666667   NaN     NaN          NaN           NaN           NaN   \n",
       "3  0.815789   NaN     NaN          NaN           NaN           NaN   \n",
       "4  0.550000   NaN     NaN          NaN           NaN           NaN   \n",
       "\n",
       "   homosexual_gay_or_lesbian  bisexual  ...  other_religion  black  white   \n",
       "0                        NaN       NaN  ...             NaN    NaN    NaN  \\\n",
       "1                        NaN       NaN  ...             NaN    NaN    NaN   \n",
       "2                        NaN       NaN  ...             NaN    NaN    NaN   \n",
       "3                        NaN       NaN  ...             NaN    NaN    NaN   \n",
       "4                        NaN       NaN  ...             NaN    NaN    NaN   \n",
       "\n",
       "   asian  latino  other_race_or_ethnicity  physical_disability   \n",
       "0    NaN     NaN                      NaN                  NaN  \\\n",
       "1    NaN     NaN                      NaN                  NaN   \n",
       "2    NaN     NaN                      NaN                  NaN   \n",
       "3    NaN     NaN                      NaN                  NaN   \n",
       "4    NaN     NaN                      NaN                  NaN   \n",
       "\n",
       "   intellectual_or_learning_disability  psychiatric_or_mental_illness   \n",
       "0                                  NaN                            NaN  \\\n",
       "1                                  NaN                            NaN   \n",
       "2                                  NaN                            NaN   \n",
       "3                                  NaN                            NaN   \n",
       "4                                  NaN                            NaN   \n",
       "\n",
       "   other_disability  \n",
       "0               NaN  \n",
       "1               NaN  \n",
       "2               NaN  \n",
       "3               NaN  \n",
       "4               NaN  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data_df_cleansed = all_data_df_cleansed.drop(columns=['id', 'split', 'created_date', 'publication_id',\n",
    "       'parent_id', 'article_id', 'rating', 'funny', 'wow', 'sad', 'likes',\n",
    "       'disagree', 'severe_toxicity', 'obscene', 'sexual_explicit',\n",
    "       'identity_attack', 'insult', 'threat', 'identity_annotator_count',\n",
    "       'toxicity_annotator_count'])\n",
    "all_data_df_cleansed.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fcbde89",
   "metadata": {},
   "source": [
    "# Prepare Disability Subset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6697880",
   "metadata": {},
   "source": [
    "## Create disability subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "793847d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "disability_df = all_data_df_cleansed[(all_data_df_cleansed[\"physical_disability\"] > 0) | \n",
    "           (all_data_df_cleansed[\"intellectual_or_learning_disability\"] > 0) | \n",
    "           (all_data_df_cleansed[\"psychiatric_or_mental_illness\"] > 0) | \n",
    "           (all_data_df_cleansed[\"other_disability\"] > 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "57642faa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18665, 27)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "disability_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43e3cc7e",
   "metadata": {},
   "source": [
    "## Add disability subtype column\n",
    "We'll add a categorical feature that specifies which of the following disability subtypes each comment corresponds to:\n",
    "\n",
    "- `physical_disability`\n",
    "- `intellectual_or_learning_disability`\n",
    "- `psychiatric_or_mental_illness`\n",
    "- `other_disability`\n",
    "\n",
    "EDA revealed that some comments have nonzero values for more than one subtype above. Since the purpose of this comment is to facilitate stratified sampling, the disability subtype label for each comment will be the subtype corresponding to the largest value for that comment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "42adc80b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxicity_binary</th>\n",
       "      <th>toxicity</th>\n",
       "      <th>male</th>\n",
       "      <th>female</th>\n",
       "      <th>transgender</th>\n",
       "      <th>other_gender</th>\n",
       "      <th>heterosexual</th>\n",
       "      <th>homosexual_gay_or_lesbian</th>\n",
       "      <th>bisexual</th>\n",
       "      <th>...</th>\n",
       "      <th>black</th>\n",
       "      <th>white</th>\n",
       "      <th>asian</th>\n",
       "      <th>latino</th>\n",
       "      <th>other_race_or_ethnicity</th>\n",
       "      <th>physical_disability</th>\n",
       "      <th>intellectual_or_learning_disability</th>\n",
       "      <th>psychiatric_or_mental_illness</th>\n",
       "      <th>other_disability</th>\n",
       "      <th>disability_subtype</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7705</th>\n",
       "      <td>No sympathy for these two knuckleheads.</td>\n",
       "      <td>1</td>\n",
       "      <td>0.689655</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>physical_disability</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8073</th>\n",
       "      <td>Wow!\\nYour progressive psychosis has become ex...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>psychiatric_or_mental_illness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8115</th>\n",
       "      <td>Or.... maybe there IS chaos because the \"presi...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>psychiatric_or_mental_illness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8125</th>\n",
       "      <td>I'll take someone who's physically ill over on...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.352941</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>psychiatric_or_mental_illness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8263</th>\n",
       "      <td>Mental Illness at work again, again, again, ag...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.842857</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>psychiatric_or_mental_illness</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           comment_text  toxicity_binary   \n",
       "7705            No sympathy for these two knuckleheads.                1  \\\n",
       "8073  Wow!\\nYour progressive psychosis has become ex...                1   \n",
       "8115  Or.... maybe there IS chaos because the \"presi...                1   \n",
       "8125  I'll take someone who's physically ill over on...                0   \n",
       "8263  Mental Illness at work again, again, again, ag...                1   \n",
       "\n",
       "      toxicity  male  female  transgender  other_gender  heterosexual   \n",
       "7705  0.689655  0.00     0.0          0.0           0.0           0.0  \\\n",
       "8073  0.800000  0.00     0.0          0.0           0.0           0.0   \n",
       "8115  0.790323  0.00     0.0          0.0           0.0           0.0   \n",
       "8125  0.352941  0.00     0.0          0.0           0.0           0.0   \n",
       "8263  0.842857  0.25     1.0          0.0           0.0           0.0   \n",
       "\n",
       "      homosexual_gay_or_lesbian  bisexual  ...  black  white  asian  latino   \n",
       "7705                        0.0       0.0  ...    0.0    0.0    0.0     0.0  \\\n",
       "8073                        0.0       0.0  ...    0.0    0.0    0.0     0.0   \n",
       "8115                        0.0       0.0  ...    0.0    0.0    0.0     0.0   \n",
       "8125                        0.0       0.0  ...    0.0    0.0    0.0     0.0   \n",
       "8263                        0.0       0.0  ...    0.0    0.0    0.0     0.0   \n",
       "\n",
       "      other_race_or_ethnicity  physical_disability   \n",
       "7705                      0.0                 0.25  \\\n",
       "8073                      0.0                 0.00   \n",
       "8115                      0.0                 0.00   \n",
       "8125                      0.0                 0.75   \n",
       "8263                      0.0                 0.00   \n",
       "\n",
       "      intellectual_or_learning_disability  psychiatric_or_mental_illness   \n",
       "7705                                  0.0                            0.0  \\\n",
       "8073                                  0.0                            1.0   \n",
       "8115                                  0.0                            1.0   \n",
       "8125                                  0.0                            1.0   \n",
       "8263                                  0.0                            1.0   \n",
       "\n",
       "      other_disability             disability_subtype  \n",
       "7705               0.0            physical_disability  \n",
       "8073               0.0  psychiatric_or_mental_illness  \n",
       "8115               0.0  psychiatric_or_mental_illness  \n",
       "8125               0.0  psychiatric_or_mental_illness  \n",
       "8263               0.0  psychiatric_or_mental_illness  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "disability_subtypes_df = disability_df[['physical_disability','intellectual_or_learning_disability','psychiatric_or_mental_illness','other_disability']]\n",
    "disability_df = disability_df.assign(disability_subtype=disability_subtypes_df.idxmax(axis=1))\n",
    "disability_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00734fce",
   "metadata": {},
   "source": [
    "## Prepare data splits for disability\n",
    "**Overview:** We'll split the disability subset into 70% train, 10% validation, and 20% test sets. Comments may have subtle differences due to disability subtypes (e.g. comments about physical disability may be different than comments about intellectual/learning disability). Therefore we'll need to do stratified sampling on the disability subtypes such that for each dataset split, the ratio for each disability subtype will be around the same.\n",
    "\n",
    "**Splitting Method**\n",
    "\n",
    "We'll use the train_test_split() method and since it only creates two splits, we'll take the following steps to create the three train/val/test splits:\n",
    "\n",
    "1. Split into group1: 80% for train and validation, and group2: 20% for test.\n",
    "1. No need to further split the test set, so leave it alone.\n",
    "1. Take the set from step 1 that combines train and validation and divide it into train and val sets. Since we want the overall ratio to be 70% train and 10% validation, the ratio for train here should be (1-1/7) and for validation it should be 1/7."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d27ec4a",
   "metadata": {},
   "source": [
    "Split the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c1d50b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into 80% combined for train and val, and 20% test\n",
    "disability_combined_df, disability_test_df = train_test_split(disability_df,\n",
    "                                       test_size=0.2,\n",
    "                                       random_state=266, stratify=disability_df['disability_subtype'])\n",
    "\n",
    "# Split into 70% for train and 10% val\n",
    "disability_train_df, disability_val_df = train_test_split(disability_combined_df,\n",
    "                                       test_size=1/7,\n",
    "                                       random_state=266, stratify=disability_combined_df['disability_subtype'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68571569",
   "metadata": {},
   "source": [
    "How big is each split?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "08e7a0f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disability_train size:  12798\n",
      "disability_val size:  2134\n",
      "disability_test size:  3733\n",
      "disability total:  18665\n",
      "disability train ratio:  0.6856683632467184\n",
      "disability val ratio:  0.11433163675328155\n",
      "disability test ratio:  0.2\n"
     ]
    }
   ],
   "source": [
    "disability_train_len = len(disability_train_df)\n",
    "disability_val_len = len(disability_val_df)\n",
    "disability_test_len = len(disability_test_df)\n",
    "disability_total = disability_train_len+disability_val_len+disability_test_len\n",
    "print('disability_train size: ', disability_train_len)\n",
    "print('disability_val size: ', disability_val_len)\n",
    "print('disability_test size: ', disability_test_len)\n",
    "print('disability total: ', disability_total)\n",
    "print('disability train ratio: ', disability_train_len/disability_total)\n",
    "print('disability val ratio: ', disability_val_len/disability_total)\n",
    "print('disability test ratio: ', disability_test_len/disability_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e0663082",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Stratified Sampling Sanity Check for Disability\n",
      "\n",
      "Disability Train\n",
      "=====================\n",
      "phys:\t 0.15010157837162055\n",
      "intel:\t 0.11525238318487263\n",
      "psych:\t 0.5926707298015315\n",
      "other_disability:\t 0.1419753086419753\n",
      "\n",
      "Disability Val\n",
      "=====================\n",
      "phys:\t 0.14995313964386128\n",
      "intel:\t 0.11527647610121837\n",
      "psych:\t 0.5927835051546392\n",
      "other_disability:\t 0.14198687910028115\n",
      "\n",
      "Disability Test\n",
      "=====================\n",
      "phys:\t 0.15001339405304046\n",
      "intel:\t 0.11518885614787035\n",
      "psych:\t 0.5928207875703188\n",
      "other_disability:\t 0.14197696222877043\n"
     ]
    }
   ],
   "source": [
    "print('\\nStratified Sampling Sanity Check for Disability')\n",
    "disability_train_phys = (disability_train_df['disability_subtype']=='physical_disability').astype(int).sum()\n",
    "disability_train_intel = (disability_train_df['disability_subtype']=='intellectual_or_learning_disability').astype(int).sum()\n",
    "disability_train_psych = (disability_train_df['disability_subtype']=='psychiatric_or_mental_illness').astype(int).sum()\n",
    "disability_train_other = (disability_train_df['disability_subtype']=='other_disability').astype(int).sum()\n",
    "disability_train_total = len(disability_train_df['disability_subtype'])\n",
    "print('\\nDisability Train')\n",
    "print('=====================')\n",
    "print('phys:\\t', disability_train_phys/disability_train_total)\n",
    "print('intel:\\t', disability_train_intel/disability_train_total)\n",
    "print('psych:\\t', disability_train_psych/disability_train_total)\n",
    "print('other_disability:\\t', disability_train_other/disability_train_total)\n",
    "\n",
    "disability_val_phys = (disability_val_df['disability_subtype']=='physical_disability').astype(int).sum()\n",
    "disability_val_intel = (disability_val_df['disability_subtype']=='intellectual_or_learning_disability').astype(int).sum()\n",
    "disability_val_psych = (disability_val_df['disability_subtype']=='psychiatric_or_mental_illness').astype(int).sum()\n",
    "disability_val_other = (disability_val_df['disability_subtype']=='other_disability').astype(int).sum()\n",
    "disability_val_total = len(disability_val_df['disability_subtype'])\n",
    "print('\\nDisability Val')\n",
    "print('=====================')\n",
    "print('phys:\\t', disability_val_phys/disability_val_total)\n",
    "print('intel:\\t', disability_val_intel/disability_val_total)\n",
    "print('psych:\\t', disability_val_psych/disability_val_total)\n",
    "print('other_disability:\\t', disability_val_other/disability_val_total)\n",
    "\n",
    "disability_test_phys = (disability_test_df['disability_subtype']=='physical_disability').astype(int).sum()\n",
    "disability_test_intel = (disability_test_df['disability_subtype']=='intellectual_or_learning_disability').astype(int).sum()\n",
    "disability_test_psych = (disability_test_df['disability_subtype']=='psychiatric_or_mental_illness').astype(int).sum()\n",
    "disability_test_other = (disability_test_df['disability_subtype']=='other_disability').astype(int).sum()\n",
    "disability_test_total = len(disability_test_df['disability_subtype'])\n",
    "print('\\nDisability Test')\n",
    "print('=====================')\n",
    "print('phys:\\t', disability_test_phys/disability_test_total)\n",
    "print('intel:\\t', disability_test_intel/disability_test_total)\n",
    "print('psych:\\t', disability_test_psych/disability_test_total)\n",
    "print('other_disability:\\t', disability_test_other/disability_test_total)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a261c7ac",
   "metadata": {},
   "source": [
    "### Export disability split datasets into csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7386d01f",
   "metadata": {},
   "outputs": [],
   "source": [
    "disability_df.to_csv('data/disability-dataset-full.csv')\n",
    "disability_train_df.to_csv('data/disability-dataset-train.csv')\n",
    "disability_val_df.to_csv('data/disability-dataset-val.csv')\n",
    "disability_test_df.to_csv('data/disability-dataset-test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e80f528c",
   "metadata": {},
   "source": [
    "### Address Data Imbalance Between Disability and Non-Disability Subsets\n",
    "All of the non-disability identities have many more records than the disability subset. For the interweaving technique, we'll want the disability and non-disability subset to be balanced. That is, we don't want whatever is learned from the disability subset to be overpowered by the non-disability subset due training on more non-disability examples. Therefore, we'll do stratified undersampling of the non-disability subsets such that they're around the same size as the disability subset. (Since disability is our focus and we're only augmenting other identity groups to help with predicting disability-related comments, we're okay with discarding data for other identity groups).\n",
    "\n",
    "#### Capture number of disability samples in disability train, val, and test set to be used in the undersampling for non-disability identities:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "98b32578",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_disability_train_samples = len(disability_train_df)\n",
    "num_disability_val_samples = len(disability_val_df)\n",
    "num_disability_test_samples = len(disability_test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57e432b8",
   "metadata": {},
   "source": [
    "# Prepare non-disability subsets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26342da2",
   "metadata": {},
   "source": [
    "**Overview**\n",
    "- We want each non-disability subset to have the following ratio: 70% train, 10% val, and 20% test.\n",
    "- Each split will be stratified on each identity's subtype.\n",
    "- Disability has 18k comments. Since there are more examples for non-disability, we'll undersample the non-disability comments to reduce it to 18k. That way the models don't favor the identity group with more examples for that identity.\n",
    "\n",
    "**Splitting Method**\n",
    "\n",
    "We'll use the train_test_split() method and since it only creates two splits, we'll take the following steps to create the three train/val/test splits:\n",
    "\n",
    "1. Split into group1: 80% for train and validation, and group2: 20% for test.\n",
    "1. No need to further split the test set, so leave it alone.\n",
    "1. Take the set from step 1 that combines train and validation and divide it into train and val sets. Since we want the overall ratio to be 70% train and 10% validation, the ratio for train here should be (1-1/7) and for validation it should be 1/7."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d09f1aa",
   "metadata": {},
   "source": [
    "## Gender subset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25c3b1ed",
   "metadata": {},
   "source": [
    "Create gender subset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3e653523",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(137722, 27)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gender_df = all_data_df_cleansed[(all_data_df_cleansed['male'] > 0) | \n",
    "           (all_data_df_cleansed['female'] > 0) | \n",
    "           (all_data_df_cleansed['transgender'] > 0) | \n",
    "           (all_data_df_cleansed['other_gender'] > 0)]\n",
    "gender_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d92306f",
   "metadata": {},
   "source": [
    "Add gender subtype column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4c17c18c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxicity_binary</th>\n",
       "      <th>toxicity</th>\n",
       "      <th>male</th>\n",
       "      <th>female</th>\n",
       "      <th>transgender</th>\n",
       "      <th>other_gender</th>\n",
       "      <th>heterosexual</th>\n",
       "      <th>homosexual_gay_or_lesbian</th>\n",
       "      <th>bisexual</th>\n",
       "      <th>...</th>\n",
       "      <th>black</th>\n",
       "      <th>white</th>\n",
       "      <th>asian</th>\n",
       "      <th>latino</th>\n",
       "      <th>other_race_or_ethnicity</th>\n",
       "      <th>physical_disability</th>\n",
       "      <th>intellectual_or_learning_disability</th>\n",
       "      <th>psychiatric_or_mental_illness</th>\n",
       "      <th>other_disability</th>\n",
       "      <th>gender_subtype</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7681</th>\n",
       "      <td>Blame men.  There's always an excuse to blame ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7682</th>\n",
       "      <td>And the woman exposing herself saying grab thi...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.728571</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7691</th>\n",
       "      <td>Are you a Pilgrim?\\nWhy arn't you growing your...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7699</th>\n",
       "      <td>No, he was accused of being a racist white man.</td>\n",
       "      <td>0</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7709</th>\n",
       "      <td>How do we fight agaisnt women who use sexual f...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           comment_text  toxicity_binary   \n",
       "7681  Blame men.  There's always an excuse to blame ...                1  \\\n",
       "7682  And the woman exposing herself saying grab thi...                1   \n",
       "7691  Are you a Pilgrim?\\nWhy arn't you growing your...                1   \n",
       "7699    No, he was accused of being a racist white man.                0   \n",
       "7709  How do we fight agaisnt women who use sexual f...                1   \n",
       "\n",
       "      toxicity  male  female  transgender  other_gender  heterosexual   \n",
       "7681  0.545455   1.0     1.0          0.0           0.0           0.0  \\\n",
       "7682  0.728571   0.0     1.0          0.0           0.0           0.0   \n",
       "7691  0.800000   1.0     0.0          0.0           0.0           0.0   \n",
       "7699  0.363636   1.0     0.0          0.0           0.0           0.0   \n",
       "7709  0.800000   1.0     1.0          0.0           0.0           0.0   \n",
       "\n",
       "      homosexual_gay_or_lesbian  bisexual  ...  black  white  asian  latino   \n",
       "7681                        0.0       0.0  ...    0.0    0.0    0.0     0.0  \\\n",
       "7682                        0.0       0.0  ...    0.0    0.0    0.0     0.0   \n",
       "7691                        0.0       0.0  ...    0.0    1.0    0.0     0.0   \n",
       "7699                        0.0       0.0  ...    0.0    1.0    0.0     0.0   \n",
       "7709                        0.0       0.0  ...    0.0    0.0    0.0     0.0   \n",
       "\n",
       "      other_race_or_ethnicity  physical_disability   \n",
       "7681                      0.0                  0.0  \\\n",
       "7682                      0.0                  0.0   \n",
       "7691                      0.0                  0.0   \n",
       "7699                      0.0                  0.0   \n",
       "7709                      0.0                  0.0   \n",
       "\n",
       "      intellectual_or_learning_disability  psychiatric_or_mental_illness   \n",
       "7681                                  0.0                            0.0  \\\n",
       "7682                                  0.0                            0.0   \n",
       "7691                                  0.0                            0.0   \n",
       "7699                                  0.0                            0.0   \n",
       "7709                                  0.0                            0.0   \n",
       "\n",
       "      other_disability  gender_subtype  \n",
       "7681               0.0            male  \n",
       "7682               0.0          female  \n",
       "7691               0.0            male  \n",
       "7699               0.0            male  \n",
       "7709               0.0            male  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gender_subtypes_df = gender_df[['male','female','transgender','other_gender']]\n",
    "gender_df = gender_df.assign(gender_subtype=gender_subtypes_df.idxmax(axis=1))\n",
    "gender_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97f5852b",
   "metadata": {},
   "source": [
    "Split the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8e6eb380",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into 80% combined for train and val, and 20% test\n",
    "# Perform undersampling by specifying train_size and test_size corresponding to disability splits\n",
    "gender_combined_df, gender_test_df = train_test_split(gender_df,\n",
    "                                       train_size=num_disability_train_samples+num_disability_val_samples,\n",
    "                                       test_size=num_disability_test_samples,\n",
    "                                       random_state=266, stratify=gender_df['gender_subtype'])\n",
    "\n",
    "# Split into 70% for train and 10% val\n",
    "gender_train_df, gender_val_df = train_test_split(gender_combined_df,\n",
    "                                       test_size=1/7,\n",
    "                                       random_state=266, stratify=gender_combined_df['gender_subtype'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b312765b",
   "metadata": {},
   "source": [
    "How big is each split?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "448b107e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gender_train size:  12798\n",
      "gender_val size:  2134\n",
      "gender_test size:  3733\n",
      "gender total:  18665\n",
      "gender train ratio:  0.6856683632467184\n",
      "gender val ratio:  0.11433163675328155\n",
      "gender test ratio:  0.2\n"
     ]
    }
   ],
   "source": [
    "gender_train_len = len(gender_train_df)\n",
    "gender_val_len = len(gender_val_df)\n",
    "gender_test_len = len(gender_test_df)\n",
    "gender_total = gender_train_len+gender_val_len+gender_test_len\n",
    "print('gender_train size: ', gender_train_len)\n",
    "print('gender_val size: ', gender_val_len)\n",
    "print('gender_test size: ', gender_test_len)\n",
    "print('gender total: ', gender_total)\n",
    "print('gender train ratio: ', gender_train_len/gender_total)\n",
    "print('gender val ratio: ', gender_val_len/gender_total)\n",
    "print('gender test ratio: ', gender_test_len/gender_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7f49ca7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Stratified Sampling Sanity Check for Gender\n",
      "\n",
      "Gender Train\n",
      "=====================\n",
      "male:\t 0.5307079231129864\n",
      "female:\t 0.42545710267229253\n",
      "transgender:\t 0.031411157993436474\n",
      "other_gender:\t 0.012423816221284576\n",
      "\n",
      "Gender Val\n",
      "=====================\n",
      "male:\t 0.5304592314901593\n",
      "female:\t 0.42549203373945643\n",
      "transgender:\t 0.03139643861293346\n",
      "other_gender:\t 0.012652296157450796\n",
      "\n",
      "Gender Test\n",
      "=====================\n",
      "male:\t 0.5306723814626306\n",
      "female:\t 0.42539512456469325\n",
      "transgender:\t 0.03134208411465309\n",
      "other_gender:\t 0.012590409858023038\n"
     ]
    }
   ],
   "source": [
    "print('\\nStratified Sampling Sanity Check for Gender')\n",
    "gender_train_male = (gender_train_df['gender_subtype']=='male').astype(int).sum()\n",
    "gender_train_female = (gender_train_df['gender_subtype']=='female').astype(int).sum()\n",
    "gender_train_trans = (gender_train_df['gender_subtype']=='transgender').astype(int).sum()\n",
    "gender_train_other = (gender_train_df['gender_subtype']=='other_gender').astype(int).sum()\n",
    "gender_train_total = len(gender_train_df['gender_subtype'])\n",
    "print('\\nGender Train')\n",
    "print('=====================')\n",
    "print('male:\\t', gender_train_male/gender_train_total)\n",
    "print('female:\\t', gender_train_female/gender_train_total)\n",
    "print('transgender:\\t', gender_train_trans/gender_train_total)\n",
    "print('other_gender:\\t', gender_train_other/gender_train_total)\n",
    "\n",
    "gender_val_male = (gender_val_df['gender_subtype']=='male').astype(int).sum()\n",
    "gender_val_female = (gender_val_df['gender_subtype']=='female').astype(int).sum()\n",
    "gender_val_trans = (gender_val_df['gender_subtype']=='transgender').astype(int).sum()\n",
    "gender_val_other = (gender_val_df['gender_subtype']=='other_gender').astype(int).sum()\n",
    "gender_val_total = len(gender_val_df['gender_subtype'])\n",
    "print('\\nGender Val')\n",
    "print('=====================')\n",
    "print('male:\\t', gender_val_male/gender_val_total)\n",
    "print('female:\\t', gender_val_female/gender_val_total)\n",
    "print('transgender:\\t', gender_val_trans/gender_val_total)\n",
    "print('other_gender:\\t', gender_val_other/gender_val_total)\n",
    "\n",
    "gender_test_male = (gender_test_df['gender_subtype']=='male').astype(int).sum()\n",
    "gender_test_female = (gender_test_df['gender_subtype']=='female').astype(int).sum()\n",
    "gender_test_trans = (gender_test_df['gender_subtype']=='transgender').astype(int).sum()\n",
    "gender_test_other = (gender_test_df['gender_subtype']=='other_gender').astype(int).sum()\n",
    "gender_test_total = len(gender_test_df['gender_subtype'])\n",
    "print('\\nGender Test')\n",
    "print('=====================')\n",
    "print('male:\\t', gender_test_male/gender_test_total)\n",
    "print('female:\\t', gender_test_female/gender_test_total)\n",
    "print('transgender:\\t', gender_test_trans/gender_test_total)\n",
    "print('other_gender:\\t', gender_test_other/gender_test_total)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce870e1c",
   "metadata": {},
   "source": [
    "Check positive/negative labels balance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bc4be446",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gender ALL Examples:\n",
      "    Total: 137722\n",
      "    Positive: 19996 (14.52% of total)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "neg, pos = np.bincount(gender_df['toxicity_binary'])\n",
    "total = neg + pos\n",
    "print('Gender ALL Examples:\\n    Total: {}\\n    Positive: {} ({:.2f}% of total)\\n'.format(\n",
    "    total, pos, 100 * pos / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "32e8c92c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gender Train Examples:\n",
      "    Total: 12798\n",
      "    Positive: 1846 (14.42% of total)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "neg, pos = np.bincount(gender_train_df['toxicity_binary'])\n",
    "total = neg + pos\n",
    "print('Gender Train Examples:\\n    Total: {}\\n    Positive: {} ({:.2f}% of total)\\n'.format(\n",
    "    total, pos, 100 * pos / total))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e35f09e7",
   "metadata": {},
   "source": [
    "### Export gender split datasets into csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "96226409",
   "metadata": {},
   "outputs": [],
   "source": [
    "gender_df.to_csv('data/gender-dataset-full.csv')\n",
    "gender_train_df.to_csv('data/gender-dataset-train.csv')\n",
    "gender_val_df.to_csv('data/gender-dataset-val.csv')\n",
    "gender_test_df.to_csv('data/gender-dataset-test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba40fe1e",
   "metadata": {},
   "source": [
    "## Sexual orientation subset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce741348",
   "metadata": {},
   "source": [
    "Create sexual orientation subset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6911615e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22649, 27)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sexual_orientation_df = all_data_df_cleansed[(all_data_df_cleansed['heterosexual'] > 0) | \n",
    "           (all_data_df_cleansed['homosexual_gay_or_lesbian'] > 0) | \n",
    "           (all_data_df_cleansed['bisexual'] > 0) | \n",
    "           (all_data_df_cleansed['other_sexual_orientation'] > 0)]\n",
    "sexual_orientation_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27c9310a",
   "metadata": {},
   "source": [
    "Add sexual orientation subtype column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "341e5002",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxicity_binary</th>\n",
       "      <th>toxicity</th>\n",
       "      <th>male</th>\n",
       "      <th>female</th>\n",
       "      <th>transgender</th>\n",
       "      <th>other_gender</th>\n",
       "      <th>heterosexual</th>\n",
       "      <th>homosexual_gay_or_lesbian</th>\n",
       "      <th>bisexual</th>\n",
       "      <th>...</th>\n",
       "      <th>black</th>\n",
       "      <th>white</th>\n",
       "      <th>asian</th>\n",
       "      <th>latino</th>\n",
       "      <th>other_race_or_ethnicity</th>\n",
       "      <th>physical_disability</th>\n",
       "      <th>intellectual_or_learning_disability</th>\n",
       "      <th>psychiatric_or_mental_illness</th>\n",
       "      <th>other_disability</th>\n",
       "      <th>sexual_orientation_subtype</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7695</th>\n",
       "      <td>Ridiculous, indeed. Although Rome does seem to...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>homosexual_gay_or_lesbian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7716</th>\n",
       "      <td>It took them long enough. And it goes against ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>homosexual_gay_or_lesbian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7746</th>\n",
       "      <td>Well now Murray can simply go for the bisexual...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>bisexual</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7890</th>\n",
       "      <td>He probably thoughthimself gay when he did not...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.453333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>homosexual_gay_or_lesbian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7894</th>\n",
       "      <td>Sodomy isn't exclusive to homosexuals. I can s...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.437500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>homosexual_gay_or_lesbian</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           comment_text  toxicity_binary   \n",
       "7695  Ridiculous, indeed. Although Rome does seem to...                1  \\\n",
       "7716  It took them long enough. And it goes against ...                0   \n",
       "7746  Well now Murray can simply go for the bisexual...                1   \n",
       "7890  He probably thoughthimself gay when he did not...                0   \n",
       "7894  Sodomy isn't exclusive to homosexuals. I can s...                0   \n",
       "\n",
       "      toxicity  male  female  transgender  other_gender  heterosexual   \n",
       "7695  0.857143   0.0     0.0          0.0           0.0           0.0  \\\n",
       "7716  0.181818   0.0     0.0          0.0           0.0           0.0   \n",
       "7746  0.800000   1.0     0.0          0.0           0.0           0.0   \n",
       "7890  0.453333   0.0     1.0          0.0           0.0           0.0   \n",
       "7894  0.437500   0.0     0.0          0.0           0.0           0.0   \n",
       "\n",
       "      homosexual_gay_or_lesbian  bisexual  ...  black  white  asian  latino   \n",
       "7695                        1.0       0.0  ...    0.0    0.0    0.0     0.0  \\\n",
       "7716                        1.0       0.0  ...    0.0    0.0    0.0     0.0   \n",
       "7746                        0.0       1.0  ...    0.0    0.0    0.0     0.0   \n",
       "7890                        1.0       0.0  ...    0.0    0.0    0.0     0.0   \n",
       "7894                        1.0       0.0  ...    0.0    0.0    0.0     0.0   \n",
       "\n",
       "      other_race_or_ethnicity  physical_disability   \n",
       "7695                      0.0                  0.0  \\\n",
       "7716                      0.0                  0.0   \n",
       "7746                      0.0                  0.0   \n",
       "7890                      0.0                  0.0   \n",
       "7894                      0.0                  0.0   \n",
       "\n",
       "      intellectual_or_learning_disability  psychiatric_or_mental_illness   \n",
       "7695                                  0.0                            0.0  \\\n",
       "7716                                  0.0                            0.0   \n",
       "7746                                  0.0                            0.0   \n",
       "7890                                  0.0                            0.0   \n",
       "7894                                  0.0                            0.0   \n",
       "\n",
       "      other_disability  sexual_orientation_subtype  \n",
       "7695               0.0   homosexual_gay_or_lesbian  \n",
       "7716               0.0   homosexual_gay_or_lesbian  \n",
       "7746               0.0                    bisexual  \n",
       "7890               0.0   homosexual_gay_or_lesbian  \n",
       "7894               0.0   homosexual_gay_or_lesbian  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sexual_orientation_subtypes_df = sexual_orientation_df[['heterosexual','homosexual_gay_or_lesbian','bisexual','other_sexual_orientation']]\n",
    "sexual_orientation_df = sexual_orientation_df.assign(sexual_orientation_subtype=sexual_orientation_subtypes_df.idxmax(axis=1))\n",
    "sexual_orientation_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf8020f8",
   "metadata": {},
   "source": [
    "Split the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "faf0324f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into 80% combined for train and val, and 20% test\n",
    "# Perform undersampling by specifying train_size and test_size corresponding to disability splits\n",
    "sexual_orientation_combined_df, sexual_orientation_test_df = train_test_split(sexual_orientation_df,\n",
    "                                       train_size=num_disability_train_samples+num_disability_val_samples,\n",
    "                                       test_size=num_disability_test_samples,\n",
    "                                       random_state=266, stratify=sexual_orientation_df['sexual_orientation_subtype'])\n",
    "\n",
    "# Split into 70% for train and 10% val\n",
    "sexual_orientation_train_df, sexual_orientation_val_df = train_test_split(sexual_orientation_combined_df,\n",
    "                                       test_size=1/7,\n",
    "                                       random_state=266, stratify=sexual_orientation_combined_df['sexual_orientation_subtype'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53775af6",
   "metadata": {},
   "source": [
    "How big is each split?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4a080e71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sexual_orientation_train size:  12798\n",
      "sexual_orientation_val size:  2134\n",
      "sexual_orientation_test size:  3733\n",
      "sexual_orientation total:  18665\n",
      "sexual_orientation train ratio:  0.6856683632467184\n",
      "sexual_orientation val ratio:  0.11433163675328155\n",
      "sexual_orientation test ratio:  0.2\n"
     ]
    }
   ],
   "source": [
    "sexual_orientation_train_len = len(sexual_orientation_train_df)\n",
    "sexual_orientation_val_len = len(sexual_orientation_val_df)\n",
    "sexual_orientation_test_len = len(sexual_orientation_test_df)\n",
    "sexual_orientation_total = sexual_orientation_train_len+sexual_orientation_val_len+sexual_orientation_test_len\n",
    "print('sexual_orientation_train size: ', sexual_orientation_train_len)\n",
    "print('sexual_orientation_val size: ', sexual_orientation_val_len)\n",
    "print('sexual_orientation_test size: ', sexual_orientation_test_len)\n",
    "print('sexual_orientation total: ', sexual_orientation_total)\n",
    "print('sexual_orientation train ratio: ', sexual_orientation_train_len/sexual_orientation_total)\n",
    "print('sexual_orientation val ratio: ', sexual_orientation_val_len/sexual_orientation_total)\n",
    "print('sexual_orientation test ratio: ', sexual_orientation_test_len/sexual_orientation_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9842549e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Stratified Sampling Sanity Check for Sexual Orientation\n",
      "\n",
      "Sexual Orientation Train\n",
      "=====================\n",
      "hetero:\t 0.10134395999374902\n",
      "homo:\t 0.7101109548366933\n",
      "bi:\t 0.042115955618065325\n",
      "other_sexual_orientation:\t 0.14642912955149243\n",
      "\n",
      "Sexual Orientation Val\n",
      "=====================\n",
      "hetero:\t 0.10121836925960637\n",
      "homo:\t 0.7104029990627929\n",
      "bi:\t 0.04217432052483599\n",
      "other_sexual_orientation:\t 0.14620431115276475\n",
      "\n",
      "Sexual Orientation test\n",
      "=====================\n",
      "hetero:\t 0.10125904098580231\n",
      "homo:\t 0.7101526922046612\n",
      "bi:\t 0.04205732654701313\n",
      "other_sexual_orientation:\t 0.14653094026252345\n"
     ]
    }
   ],
   "source": [
    "print('\\nStratified Sampling Sanity Check for Sexual Orientation')\n",
    "sexual_orientation_train_hetero = (sexual_orientation_train_df['sexual_orientation_subtype']=='heterosexual').astype(int).sum()\n",
    "sexual_orientation_train_homo = (sexual_orientation_train_df['sexual_orientation_subtype']=='homosexual_gay_or_lesbian').astype(int).sum()\n",
    "sexual_orientation_train_bi = (sexual_orientation_train_df['sexual_orientation_subtype']=='bisexual').astype(int).sum()\n",
    "sexual_orientation_train_other = (sexual_orientation_train_df['sexual_orientation_subtype']=='other_sexual_orientation').astype(int).sum()\n",
    "sexual_orientation_train_total = len(sexual_orientation_train_df['sexual_orientation_subtype'])\n",
    "print('\\nSexual Orientation Train')\n",
    "print('=====================')\n",
    "print('hetero:\\t', sexual_orientation_train_hetero/sexual_orientation_train_total)\n",
    "print('homo:\\t', sexual_orientation_train_homo/sexual_orientation_train_total)\n",
    "print('bi:\\t', sexual_orientation_train_bi/sexual_orientation_train_total)\n",
    "print('other_sexual_orientation:\\t', sexual_orientation_train_other/sexual_orientation_train_total)\n",
    "\n",
    "sexual_orientation_val_hetero = (sexual_orientation_val_df['sexual_orientation_subtype']=='heterosexual').astype(int).sum()\n",
    "sexual_orientation_val_homo = (sexual_orientation_val_df['sexual_orientation_subtype']=='homosexual_gay_or_lesbian').astype(int).sum()\n",
    "sexual_orientation_val_bi = (sexual_orientation_val_df['sexual_orientation_subtype']=='bisexual').astype(int).sum()\n",
    "sexual_orientation_val_other = (sexual_orientation_val_df['sexual_orientation_subtype']=='other_sexual_orientation').astype(int).sum()\n",
    "sexual_orientation_val_total = len(sexual_orientation_val_df['sexual_orientation_subtype'])\n",
    "print('\\nSexual Orientation Val')\n",
    "print('=====================')\n",
    "print('hetero:\\t', sexual_orientation_val_hetero/sexual_orientation_val_total)\n",
    "print('homo:\\t', sexual_orientation_val_homo/sexual_orientation_val_total)\n",
    "print('bi:\\t', sexual_orientation_val_bi/sexual_orientation_val_total)\n",
    "print('other_sexual_orientation:\\t', sexual_orientation_val_other/sexual_orientation_val_total)\n",
    "\n",
    "sexual_orientation_test_hetero = (sexual_orientation_test_df['sexual_orientation_subtype']=='heterosexual').astype(int).sum()\n",
    "sexual_orientation_test_homo = (sexual_orientation_test_df['sexual_orientation_subtype']=='homosexual_gay_or_lesbian').astype(int).sum()\n",
    "sexual_orientation_test_bi = (sexual_orientation_test_df['sexual_orientation_subtype']=='bisexual').astype(int).sum()\n",
    "sexual_orientation_test_other = (sexual_orientation_test_df['sexual_orientation_subtype']=='other_sexual_orientation').astype(int).sum()\n",
    "sexual_orientation_test_total = len(sexual_orientation_test_df['sexual_orientation_subtype'])\n",
    "print('\\nSexual Orientation test')\n",
    "print('=====================')\n",
    "print('hetero:\\t', sexual_orientation_test_hetero/sexual_orientation_test_total)\n",
    "print('homo:\\t', sexual_orientation_test_homo/sexual_orientation_test_total)\n",
    "print('bi:\\t', sexual_orientation_test_bi/sexual_orientation_test_total)\n",
    "print('other_sexual_orientation:\\t', sexual_orientation_test_other/sexual_orientation_test_total)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10cb0f29",
   "metadata": {},
   "source": [
    "Check positive/negative labels balance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "dc28c4e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sexual Orientation ALL Examples:\n",
      "    Total: 22649\n",
      "    Positive: 5119 (22.60% of total)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "neg, pos = np.bincount(sexual_orientation_df['toxicity_binary'])\n",
    "total = neg + pos\n",
    "print('Sexual Orientation ALL Examples:\\n    Total: {}\\n    Positive: {} ({:.2f}% of total)\\n'.format(\n",
    "    total, pos, 100 * pos / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "355baf0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sexual Orientation Train Examples:\n",
      "    Total: 12798\n",
      "    Positive: 2834 (22.14% of total)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "neg, pos = np.bincount(sexual_orientation_train_df['toxicity_binary'])\n",
    "total = neg + pos\n",
    "print('Sexual Orientation Train Examples:\\n    Total: {}\\n    Positive: {} ({:.2f}% of total)\\n'.format(\n",
    "    total, pos, 100 * pos / total))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b7a6b6d",
   "metadata": {},
   "source": [
    "### Export sexual orientation split datasets into csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bef9bdb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sexual_orientation_df.to_csv('data/sexual_orientation-dataset-full.csv')\n",
    "sexual_orientation_train_df.to_csv('data/sexual_orientation-dataset-train.csv')\n",
    "sexual_orientation_val_df.to_csv('data/sexual_orientation-dataset-val.csv')\n",
    "sexual_orientation_test_df.to_csv('data/sexual_orientation-dataset-test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81e635cc",
   "metadata": {},
   "source": [
    "## Religion subset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6513c5f6",
   "metadata": {},
   "source": [
    "Create religion subset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "67b2cc77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(137722, 28)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "religion_df = all_data_df_cleansed[(all_data_df_cleansed['christian'] > 0) | \n",
    "           (all_data_df_cleansed['jewish'] > 0) | \n",
    "           (all_data_df_cleansed['muslim'] > 0) | \n",
    "           (all_data_df_cleansed['hindu'] > 0) | \n",
    "           (all_data_df_cleansed['buddhist'] > 0) | \n",
    "           (all_data_df_cleansed['atheist'] > 0) | \n",
    "           (all_data_df_cleansed['other_religion'] > 0)]\n",
    "gender_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c724102a",
   "metadata": {},
   "source": [
    "Add religion subtype column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f694fbb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxicity_binary</th>\n",
       "      <th>toxicity</th>\n",
       "      <th>male</th>\n",
       "      <th>female</th>\n",
       "      <th>transgender</th>\n",
       "      <th>other_gender</th>\n",
       "      <th>heterosexual</th>\n",
       "      <th>homosexual_gay_or_lesbian</th>\n",
       "      <th>bisexual</th>\n",
       "      <th>...</th>\n",
       "      <th>black</th>\n",
       "      <th>white</th>\n",
       "      <th>asian</th>\n",
       "      <th>latino</th>\n",
       "      <th>other_race_or_ethnicity</th>\n",
       "      <th>physical_disability</th>\n",
       "      <th>intellectual_or_learning_disability</th>\n",
       "      <th>psychiatric_or_mental_illness</th>\n",
       "      <th>other_disability</th>\n",
       "      <th>religion_subtype</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7678</th>\n",
       "      <td>OH yes - Were those evil Christian Missionarie...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>christian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7689</th>\n",
       "      <td>Lela, you admit no records exist to support yo...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>atheist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7701</th>\n",
       "      <td>The robot censor seems disinclined to accept s...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>muslim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7704</th>\n",
       "      <td>Agreed: there's no equivalence. What is stoppi...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>christian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7716</th>\n",
       "      <td>It took them long enough. And it goes against ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>christian</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           comment_text  toxicity_binary   \n",
       "7678  OH yes - Were those evil Christian Missionarie...                1  \\\n",
       "7689  Lela, you admit no records exist to support yo...                0   \n",
       "7701  The robot censor seems disinclined to accept s...                1   \n",
       "7704  Agreed: there's no equivalence. What is stoppi...                1   \n",
       "7716  It took them long enough. And it goes against ...                0   \n",
       "\n",
       "      toxicity  male  female  transgender  other_gender  heterosexual   \n",
       "7678  0.800000   0.0     0.0          0.0           0.0           0.0  \\\n",
       "7689  0.111111   0.0     0.0          0.0           0.0           0.0   \n",
       "7701  0.800000   0.0     0.0          0.0           0.0           0.0   \n",
       "7704  0.800000   0.0     0.0          0.0           0.0           0.0   \n",
       "7716  0.181818   0.0     0.0          0.0           0.0           0.0   \n",
       "\n",
       "      homosexual_gay_or_lesbian  bisexual  ...  black  white  asian  latino   \n",
       "7678                        0.0       0.0  ...    0.0   0.00    0.0     0.0  \\\n",
       "7689                        0.0       0.0  ...    0.0   0.00    0.0     0.0   \n",
       "7701                        0.0       0.0  ...    1.0   0.75    0.0     0.0   \n",
       "7704                        0.0       0.0  ...    0.0   0.00    0.0     0.0   \n",
       "7716                        1.0       0.0  ...    0.0   0.00    0.0     0.0   \n",
       "\n",
       "      other_race_or_ethnicity  physical_disability   \n",
       "7678                      0.0                  0.0  \\\n",
       "7689                      0.0                  0.0   \n",
       "7701                      0.0                  0.0   \n",
       "7704                      0.0                  0.0   \n",
       "7716                      0.0                  0.0   \n",
       "\n",
       "      intellectual_or_learning_disability  psychiatric_or_mental_illness   \n",
       "7678                                  0.0                            0.0  \\\n",
       "7689                                  0.0                            0.0   \n",
       "7701                                  0.0                            0.0   \n",
       "7704                                  0.0                            0.0   \n",
       "7716                                  0.0                            0.0   \n",
       "\n",
       "      other_disability  religion_subtype  \n",
       "7678               0.0         christian  \n",
       "7689               0.0           atheist  \n",
       "7701               0.0            muslim  \n",
       "7704               0.0         christian  \n",
       "7716               0.0         christian  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "religion_subtypes_df = religion_df[['christian','jewish','muslim','hindu','buddhist','atheist','other_religion']]\n",
    "religion_df = religion_df.assign(religion_subtype=religion_subtypes_df.idxmax(axis=1))\n",
    "religion_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9695bc2",
   "metadata": {},
   "source": [
    "Split the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1fa718c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into 80% combined for train and val, and 20% test\n",
    "religion_combined_df, religion_test_df = train_test_split(religion_df,\n",
    "                                       train_size=num_disability_train_samples+num_disability_val_samples,\n",
    "                                       test_size=num_disability_test_samples,\n",
    "                                       random_state=266, stratify=religion_df['religion_subtype'])\n",
    "\n",
    "# Split into 70% for train and 10% val\n",
    "religion_train_df, religion_val_df = train_test_split(religion_combined_df,\n",
    "                                       test_size=1/7,\n",
    "                                       random_state=266, stratify=religion_combined_df['religion_subtype'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e46bbf1",
   "metadata": {},
   "source": [
    "How big is each split?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a837cc71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "religion_train size:  12798\n",
      "religion_val size:  2134\n",
      "religion_test size:  3733\n",
      "religion total:  18665\n",
      "religion train ratio:  0.6856683632467184\n",
      "religion val ratio:  0.11433163675328155\n",
      "religion test ratio:  0.2\n"
     ]
    }
   ],
   "source": [
    "religion_train_len = len(religion_train_df)\n",
    "religion_val_len = len(religion_val_df)\n",
    "religion_test_len = len(religion_test_df)\n",
    "religion_total = religion_train_len+religion_val_len+religion_test_len\n",
    "print('religion_train size: ', religion_train_len)\n",
    "print('religion_val size: ', religion_val_len)\n",
    "print('religion_test size: ', religion_test_len)\n",
    "print('religion total: ', religion_total)\n",
    "print('religion train ratio: ', religion_train_len/religion_total)\n",
    "print('religion val ratio: ', religion_val_len/religion_total)\n",
    "print('religion test ratio: ', religion_test_len/religion_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5d8f6d9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Stratified Sampling Sanity Check for Religion\n",
      "\n",
      "Religion Train\n",
      "=====================\n",
      "christian:\t 0.6294733552117519\n",
      "jewish:\t 0.07172995780590717\n",
      "muslim:\t 0.23261447101109547\n",
      "hindu:\t 0.007735583684950774\n",
      "other_religion:\t 0.037115174245975935\n",
      "\n",
      "Religion Val\n",
      "=====================\n",
      "christian:\t 0.6293345829428304\n",
      "jewish:\t 0.07169634489222118\n",
      "muslim:\t 0.23289597000937207\n",
      "hindu:\t 0.007497656982193065\n",
      "other_religion:\t 0.037019681349578254\n",
      "\n",
      "Religion Test\n",
      "=====================\n",
      "christian:\t 0.6295204929011519\n",
      "jewish:\t 0.07179212429681221\n",
      "muslim:\t 0.2325207607822127\n",
      "hindu:\t 0.0077685507634610235\n",
      "other_religion:\t 0.03696758639164211\n"
     ]
    }
   ],
   "source": [
    "print('\\nStratified Sampling Sanity Check for Religion')\n",
    "religion_train_christian = (religion_train_df['religion_subtype']=='christian').astype(int).sum()\n",
    "religion_train_jewish = (religion_train_df['religion_subtype']=='jewish').astype(int).sum()\n",
    "religion_train_muslim = (religion_train_df['religion_subtype']=='muslim').astype(int).sum()\n",
    "religion_train_hindu = (religion_train_df['religion_subtype']=='hindu').astype(int).sum()\n",
    "religion_train_other = (religion_train_df['religion_subtype']=='other_religion').astype(int).sum()\n",
    "religion_train_total = len(religion_train_df['religion_subtype'])\n",
    "print('\\nReligion Train')\n",
    "print('=====================')\n",
    "print('christian:\\t', religion_train_christian/religion_train_total)\n",
    "print('jewish:\\t', religion_train_jewish/religion_train_total)\n",
    "print('muslim:\\t', religion_train_muslim/religion_train_total)\n",
    "print('hindu:\\t', religion_train_hindu/religion_train_total)\n",
    "print('other_religion:\\t', religion_train_other/religion_train_total)\n",
    "\n",
    "religion_val_christian = (religion_val_df['religion_subtype']=='christian').astype(int).sum()\n",
    "religion_val_jewish = (religion_val_df['religion_subtype']=='jewish').astype(int).sum()\n",
    "religion_val_muslim = (religion_val_df['religion_subtype']=='muslim').astype(int).sum()\n",
    "religion_val_hindu = (religion_val_df['religion_subtype']=='hindu').astype(int).sum()\n",
    "religion_val_other = (religion_val_df['religion_subtype']=='other_religion').astype(int).sum()\n",
    "religion_val_total = len(religion_val_df['religion_subtype'])\n",
    "print('\\nReligion Val')\n",
    "print('=====================')\n",
    "print('christian:\\t', religion_val_christian/religion_val_total)\n",
    "print('jewish:\\t', religion_val_jewish/religion_val_total)\n",
    "print('muslim:\\t', religion_val_muslim/religion_val_total)\n",
    "print('hindu:\\t', religion_val_hindu/religion_val_total)\n",
    "print('other_religion:\\t', religion_val_other/religion_val_total)\n",
    "\n",
    "religion_test_christian = (religion_test_df['religion_subtype']=='christian').astype(int).sum()\n",
    "religion_test_jewish = (religion_test_df['religion_subtype']=='jewish').astype(int).sum()\n",
    "religion_test_muslim = (religion_test_df['religion_subtype']=='muslim').astype(int).sum()\n",
    "religion_test_hindu = (religion_test_df['religion_subtype']=='hindu').astype(int).sum()\n",
    "religion_test_other = (religion_test_df['religion_subtype']=='other_religion').astype(int).sum()\n",
    "religion_test_total = len(religion_test_df['religion_subtype'])\n",
    "print('\\nReligion Test')\n",
    "print('=====================')\n",
    "print('christian:\\t', religion_test_christian/religion_test_total)\n",
    "print('jewish:\\t', religion_test_jewish/religion_test_total)\n",
    "print('muslim:\\t', religion_test_muslim/religion_test_total)\n",
    "print('hindu:\\t', religion_test_hindu/religion_test_total)\n",
    "print('other_religion:\\t', religion_test_other/religion_test_total)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da30543a",
   "metadata": {},
   "source": [
    "Check positive/negative labels balance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5272dd05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Religion ALL Examples:\n",
      "    Total: 101410\n",
      "    Positive: 12581 (12.41% of total)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "neg, pos = np.bincount(religion_df['toxicity_binary'])\n",
    "total = neg + pos\n",
    "print('Religion ALL Examples:\\n    Total: {}\\n    Positive: {} ({:.2f}% of total)\\n'.format(\n",
    "    total, pos, 100 * pos / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0292c5c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Religion Train Examples:\n",
      "    Total: 12798\n",
      "    Positive: 1575 (12.31% of total)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "neg, pos = np.bincount(religion_train_df['toxicity_binary'])\n",
    "total = neg + pos\n",
    "print('Religion Train Examples:\\n    Total: {}\\n    Positive: {} ({:.2f}% of total)\\n'.format(\n",
    "    total, pos, 100 * pos / total))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86f94908",
   "metadata": {},
   "source": [
    "### Export religion split datasets into csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "44e58d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "religion_df.to_csv('data/religion-dataset-full.csv')\n",
    "religion_train_df.to_csv('data/religion-dataset-train.csv')\n",
    "religion_val_df.to_csv('data/religion-dataset-val.csv')\n",
    "religion_test_df.to_csv('data/religion-dataset-test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62d2dfc6",
   "metadata": {},
   "source": [
    "## Race subset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa7e917b",
   "metadata": {},
   "source": [
    "Create race subset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c4d46ee3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(71648, 27)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "race_df = all_data_df_cleansed[(all_data_df_cleansed['black'] > 0) | \n",
    "           (all_data_df_cleansed['white'] > 0) | \n",
    "           (all_data_df_cleansed['asian'] > 0) | \n",
    "           (all_data_df_cleansed['latino'] > 0) | \n",
    "           (all_data_df_cleansed['other_race_or_ethnicity'] > 0)]\n",
    "race_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8d264d7",
   "metadata": {},
   "source": [
    "Add race subtype column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "10452b9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxicity_binary</th>\n",
       "      <th>toxicity</th>\n",
       "      <th>male</th>\n",
       "      <th>female</th>\n",
       "      <th>transgender</th>\n",
       "      <th>other_gender</th>\n",
       "      <th>heterosexual</th>\n",
       "      <th>homosexual_gay_or_lesbian</th>\n",
       "      <th>bisexual</th>\n",
       "      <th>...</th>\n",
       "      <th>black</th>\n",
       "      <th>white</th>\n",
       "      <th>asian</th>\n",
       "      <th>latino</th>\n",
       "      <th>other_race_or_ethnicity</th>\n",
       "      <th>physical_disability</th>\n",
       "      <th>intellectual_or_learning_disability</th>\n",
       "      <th>psychiatric_or_mental_illness</th>\n",
       "      <th>other_disability</th>\n",
       "      <th>race_subtype</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7679</th>\n",
       "      <td>Why is this black racist crap still on the G&amp;M...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.757143</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>black</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7680</th>\n",
       "      <td>even up here.......BLACKS!</td>\n",
       "      <td>1</td>\n",
       "      <td>0.688525</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>black</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7684</th>\n",
       "      <td>\"Let's get the black folks and the white folks...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>black</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7691</th>\n",
       "      <td>Are you a Pilgrim?\\nWhy arn't you growing your...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>white</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7696</th>\n",
       "      <td>And there it is. Our president is a white supr...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.507042</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>white</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           comment_text  toxicity_binary   \n",
       "7679  Why is this black racist crap still on the G&M...                1  \\\n",
       "7680                         even up here.......BLACKS!                1   \n",
       "7684  \"Let's get the black folks and the white folks...                1   \n",
       "7691  Are you a Pilgrim?\\nWhy arn't you growing your...                1   \n",
       "7696  And there it is. Our president is a white supr...                1   \n",
       "\n",
       "      toxicity  male  female  transgender  other_gender  heterosexual   \n",
       "7679  0.757143   0.0     0.0          0.0           0.0           0.0  \\\n",
       "7680  0.688525   0.0     0.0          0.0           0.0           0.0   \n",
       "7684  0.736842   0.0     0.0          0.0           0.0           0.0   \n",
       "7691  0.800000   1.0     0.0          0.0           0.0           0.0   \n",
       "7696  0.507042   0.0     0.0          0.0           0.0           0.0   \n",
       "\n",
       "      homosexual_gay_or_lesbian  bisexual  ...  black  white  asian  latino   \n",
       "7679                        0.0       0.0  ...    1.0   0.75    0.0     0.0  \\\n",
       "7680                        0.0       0.0  ...    1.0   0.00    0.0     0.0   \n",
       "7684                        0.0       0.0  ...    1.0   1.00    0.0     0.0   \n",
       "7691                        0.0       0.0  ...    0.0   1.00    0.0     0.0   \n",
       "7696                        0.0       0.0  ...    0.0   1.00    0.0     0.0   \n",
       "\n",
       "      other_race_or_ethnicity  physical_disability   \n",
       "7679                      0.0                  0.0  \\\n",
       "7680                      0.0                  0.0   \n",
       "7684                      0.0                  0.0   \n",
       "7691                      0.0                  0.0   \n",
       "7696                      0.0                  0.0   \n",
       "\n",
       "      intellectual_or_learning_disability  psychiatric_or_mental_illness   \n",
       "7679                                  0.0                            0.0  \\\n",
       "7680                                  0.0                            0.0   \n",
       "7684                                  0.0                            0.0   \n",
       "7691                                  0.0                            0.0   \n",
       "7696                                  0.0                            0.0   \n",
       "\n",
       "      other_disability  race_subtype  \n",
       "7679               0.0         black  \n",
       "7680               0.0         black  \n",
       "7684               0.0         black  \n",
       "7691               0.0         white  \n",
       "7696               0.0         white  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "race_subtypes_df = race_df[['black', 'white', 'asian','latino', 'other_race_or_ethnicity']]\n",
    "race_df = race_df.assign(race_subtype=race_subtypes_df.idxmax(axis=1))\n",
    "race_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d6d853b",
   "metadata": {},
   "source": [
    "Split the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2b3ff30b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into 80% combined for train and val, and 20% test\n",
    "# Perform undersampling by specifying train_size and test_size corresponding to disability splits\n",
    "race_combined_df, race_test_df = train_test_split(race_df,\n",
    "                                       train_size=num_disability_train_samples+num_disability_val_samples,\n",
    "                                       test_size=num_disability_test_samples,\n",
    "                                       random_state=266, stratify=race_df['race_subtype'])\n",
    "\n",
    "# Split into 70% for train and 10% val\n",
    "race_train_df, race_val_df = train_test_split(race_combined_df,\n",
    "                                       test_size=1/7,\n",
    "                                       random_state=266, stratify=race_combined_df['race_subtype'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c116d6a0",
   "metadata": {},
   "source": [
    "How big is each split?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c189e111",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "race_train size:  12798\n",
      "race_val size:  2134\n",
      "race_test size:  3733\n",
      "race total:  18665\n",
      "race train ratio:  0.6856683632467184\n",
      "race val ratio:  0.11433163675328155\n",
      "race test ratio:  0.2\n"
     ]
    }
   ],
   "source": [
    "race_train_len = len(race_train_df)\n",
    "race_val_len = len(race_val_df)\n",
    "race_test_len = len(race_test_df)\n",
    "race_total = race_train_len+race_val_len+race_test_len\n",
    "print('race_train size: ', race_train_len)\n",
    "print('race_val size: ', race_val_len)\n",
    "print('race_test size: ', race_test_len)\n",
    "print('race total: ', race_total)\n",
    "print('race train ratio: ', race_train_len/race_total)\n",
    "print('race val ratio: ', race_val_len/race_total)\n",
    "print('race test ratio: ', race_test_len/race_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8555d415",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Stratified Sampling Sanity Check for race\n",
      "\n",
      "Race Train\n",
      "=====================\n",
      "black:\t 0.24910142209720268\n",
      "white:\t 0.3663072355055477\n",
      "asian:\t 0.13892795749335834\n",
      "latino:\t 0.07188623222378497\n",
      "other_race_or_ethnicity:\t 0.17377715268010627\n",
      "\n",
      "Race Val\n",
      "=====================\n",
      "black:\t 0.2492970946579194\n",
      "white:\t 0.36644798500468606\n",
      "asian:\t 0.1387066541705717\n",
      "latino:\t 0.07169634489222118\n",
      "other_race_or_ethnicity:\t 0.1738519212746017\n",
      "\n",
      "Race Test\n",
      "=====================\n",
      "black:\t 0.24912938655237074\n",
      "white:\t 0.3664612911867131\n",
      "asian:\t 0.13876238949906242\n",
      "latino:\t 0.07179212429681221\n",
      "other_race_or_ethnicity:\t 0.17385480846504153\n"
     ]
    }
   ],
   "source": [
    "print('\\nStratified Sampling Sanity Check for race')\n",
    "race_train_black = (race_train_df['race_subtype']=='black').astype(int).sum()\n",
    "race_train_white = (race_train_df['race_subtype']=='white').astype(int).sum()\n",
    "race_train_asian = (race_train_df['race_subtype']=='asian').astype(int).sum()\n",
    "race_train_latino = (race_train_df['race_subtype']=='latino').astype(int).sum()\n",
    "race_train_other = (race_train_df['race_subtype']=='other_race_or_ethnicity').astype(int).sum()\n",
    "race_train_total = len(race_train_df['race_subtype'])\n",
    "print('\\nRace Train')\n",
    "print('=====================')\n",
    "print('black:\\t', race_train_black/race_train_total)\n",
    "print('white:\\t', race_train_white/race_train_total)\n",
    "print('asian:\\t', race_train_asian/race_train_total)\n",
    "print('latino:\\t', race_train_latino/race_train_total)\n",
    "print('other_race_or_ethnicity:\\t', race_train_other/race_train_total)\n",
    "\n",
    "race_val_black = (race_val_df['race_subtype']=='black').astype(int).sum()\n",
    "race_val_white = (race_val_df['race_subtype']=='white').astype(int).sum()\n",
    "race_val_asian = (race_val_df['race_subtype']=='asian').astype(int).sum()\n",
    "race_val_latino = (race_val_df['race_subtype']=='latino').astype(int).sum()\n",
    "race_val_other = (race_val_df['race_subtype']=='other_race_or_ethnicity').astype(int).sum()\n",
    "race_val_total = len(race_val_df['race_subtype'])\n",
    "print('\\nRace Val')\n",
    "print('=====================')\n",
    "print('black:\\t', race_val_black/race_val_total)\n",
    "print('white:\\t', race_val_white/race_val_total)\n",
    "print('asian:\\t', race_val_asian/race_val_total)\n",
    "print('latino:\\t', race_val_latino/race_val_total)\n",
    "print('other_race_or_ethnicity:\\t', race_val_other/race_val_total)\n",
    "\n",
    "race_test_black = (race_test_df['race_subtype']=='black').astype(int).sum()\n",
    "race_test_white = (race_test_df['race_subtype']=='white').astype(int).sum()\n",
    "race_test_asian = (race_test_df['race_subtype']=='asian').astype(int).sum()\n",
    "race_test_latino = (race_test_df['race_subtype']=='latino').astype(int).sum()\n",
    "race_test_other = (race_test_df['race_subtype']=='other_race_or_ethnicity').astype(int).sum()\n",
    "race_test_total = len(race_test_df['race_subtype'])\n",
    "print('\\nRace Test')\n",
    "print('=====================')\n",
    "print('black:\\t', race_test_black/race_test_total)\n",
    "print('white:\\t', race_test_white/race_test_total)\n",
    "print('asian:\\t', race_test_asian/race_test_total)\n",
    "print('latino:\\t', race_test_latino/race_test_total)\n",
    "print('other_race_or_ethnicity:\\t', race_test_other/race_test_total)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "568d79b4",
   "metadata": {},
   "source": [
    "Check positive/negative labels balance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b4544b10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Race ALL Examples:\n",
      "    Total: 71648\n",
      "    Positive: 14682 (20.49% of total)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "neg, pos = np.bincount(race_df['toxicity_binary'])\n",
    "total = neg + pos\n",
    "print('Race ALL Examples:\\n    Total: {}\\n    Positive: {} ({:.2f}% of total)\\n'.format(\n",
    "    total, pos, 100 * pos / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c6934a2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Race Train Examples:\n",
      "    Total: 12798\n",
      "    Positive: 2621 (20.48% of total)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "neg, pos = np.bincount(race_train_df['toxicity_binary'])\n",
    "total = neg + pos\n",
    "print('Race Train Examples:\\n    Total: {}\\n    Positive: {} ({:.2f}% of total)\\n'.format(\n",
    "    total, pos, 100 * pos / total))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65971a77",
   "metadata": {},
   "source": [
    "### Export race split datasets into csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "fee82a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "race_df.to_csv('data/race-dataset-full.csv')\n",
    "race_train_df.to_csv('data/race-dataset-train.csv')\n",
    "race_val_df.to_csv('data/race-dataset-val.csv')\n",
    "race_test_df.to_csv('data/race-dataset-test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf97be94",
   "metadata": {},
   "source": [
    "# Reference code: How to load split data for use in our models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14cfa5c1",
   "metadata": {},
   "source": [
    "Load the csv files for each data split with the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b45239be",
   "metadata": {},
   "outputs": [],
   "source": [
    "disability_df_train = pd.read_csv('data/disability-dataset-train.csv')\n",
    "disability_df_val = pd.read_csv('data/disability-dataset-val.csv')\n",
    "disability_df_test = pd.read_csv('data/disability-dataset-test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "effdefcb",
   "metadata": {},
   "source": [
    "Now that we loaded our data, we'll need their labels and text examples in the form of tensors. Use the code below to accomplish this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d99c6ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Form tensors of labels and features.\n",
    "disability_train_labels = tf.convert_to_tensor(disability_df_train['toxicity_binary'])\n",
    "disability_val_labels = tf.convert_to_tensor(disability_df_val['toxicity_binary'])\n",
    "disability_test_labels = tf.convert_to_tensor(disability_df_test['toxicity_binary'])\n",
    "\n",
    "disability_train_examples = tf.convert_to_tensor(disability_df_train['comment_text'])\n",
    "disability_val_examples = tf.convert_to_tensor(disability_df_val['comment_text'])\n",
    "disability_test_examples = tf.convert_to_tensor(disability_df_test['comment_text'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 (tensorflow)",
   "language": "python",
   "name": "w266tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
