{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0f02e155",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "65f3fdb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "166edf60",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cabanela/anaconda3/envs/w266tensorflow/lib/python3.10/site-packages/tensorflow_addons/utils/ensure_tf_install.py:53: UserWarning: Tensorflow Addons supports using Python ops for all Tensorflow versions above or equal to 2.7.0 and strictly below 2.10.0 (nightly versions are not supported). \n",
      " The versions of TensorFlow you are currently using is 2.12.0 and is not supported. \n",
      "Some things might work, some things might not.\n",
      "If you were to encounter a bug, do not file an issue.\n",
      "If you want to make sure you're using a tested and supported configuration, either change the TensorFlow version or the TensorFlow Addons's version. \n",
      "You can find the compatibility matrix in TensorFlow Addon's readme:\n",
      "https://github.com/tensorflow/addons\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "import transformers\n",
    "from transformers import AutoTokenizer,TFRobertaModel\n",
    "\n",
    "import pytz\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "061a517d",
   "metadata": {},
   "source": [
    "## Resources Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "92ed989b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REPLICAS:  1\n"
     ]
    }
   ],
   "source": [
    "# Detect hardware, return appropriate distribution strategy\n",
    "try:\n",
    "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
    "    print('Running on TPU ', tpu.master())\n",
    "except ValueError:\n",
    "    tpu = None\n",
    "\n",
    "if tpu:\n",
    "    tf.config.experimental_connect_to_cluster(tpu)\n",
    "    tf.tpu.experimental.initialize_tpu_system(tpu)\n",
    "    strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
    "else:\n",
    "    # Default distribution strategy in Tensorflow. Works on CPU and single GPU.\n",
    "    strategy = tf.distribute.get_strategy()\n",
    "\n",
    "print(\"REPLICAS: \", strategy.num_replicas_in_sync)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "113295a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python Platform: macOS-12.5-arm64-arm-64bit\n",
      "Tensor Flow Version: 2.12.0\n",
      "Keras Version: 2.12.0\n",
      "\n",
      "Python 3.10.10 | packaged by conda-forge | (main, Mar 24 2023, 20:12:31) [Clang 14.0.6 ]\n",
      "Pandas 2.0.0\n",
      "Scikit-Learn 1.2.2\n",
      "GPU is available\n"
     ]
    }
   ],
   "source": [
    "# What version of Python do you have?\n",
    "import sys\n",
    "import platform\n",
    "import sklearn as sk\n",
    "\n",
    "print(f\"Python Platform: {platform.platform()}\")\n",
    "print(f\"Tensor Flow Version: {tf.__version__}\")\n",
    "print(f\"Keras Version: {tf.keras.__version__}\")\n",
    "print()\n",
    "print(f\"Python {sys.version}\")\n",
    "print(f\"Pandas {pd.__version__}\")\n",
    "print(f\"Scikit-Learn {sk.__version__}\")\n",
    "gpu = len(tf.config.list_physical_devices('GPU'))>0\n",
    "print(\"GPU is\", \"available\" if gpu else \"NOT AVAILABLE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac6533ca",
   "metadata": {},
   "source": [
    "## Functions and Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "653cd9b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_arrays(df):\n",
    "  X = df['comment_text'].to_numpy()\n",
    "  y = df['toxicity_binary'].to_numpy()\n",
    "  return X, y\n",
    "\n",
    "def load_data(group):\n",
    "  df_train = pd.read_csv('data/' + group + '-dataset-train.csv')\n",
    "  df_val = pd.read_csv('data/' + group + '-dataset-val.csv')\n",
    "  df_test = pd.read_csv('data/' + group + '-dataset-test.csv')\n",
    "\n",
    "  X_train, y_train = to_arrays(df_train)\n",
    "  X_val, y_val = to_arrays(df_val)\n",
    "  X_test, y_test = to_arrays(df_test)\n",
    "\n",
    "  return X_train, y_train, X_test, y_test, X_val, y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9b7be9ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_SEQUENCE_LENGTH = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "023b0626",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenizing_pipeline(X, tokenizer):\n",
    "  bert_tokenized = tokenizer(list(X),\n",
    "                max_length=MAX_SEQUENCE_LENGTH,\n",
    "                truncation=True,\n",
    "                padding='max_length',\n",
    "                return_tensors='tf')\n",
    "  bert_inputs = [bert_tokenized.input_ids,\n",
    "                 bert_tokenized.token_type_ids,\n",
    "                 bert_tokenized.attention_mask]\n",
    "  return bert_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f486369a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_bertweet_cls_model(max_sequence_length=MAX_SEQUENCE_LENGTH,\n",
    "                          hidden_size=100, \n",
    "                          dropout=0.3,\n",
    "                          learning_rate=0.0001,\n",
    "                          num_train_layers=0):\n",
    "\n",
    "    # freeze all pre-trained BERTweet layers\n",
    "    if num_train_layers == 0:\n",
    "      bertweet_model.trainable = False\n",
    "\n",
    "    # partially freeze the first n pre-trained BERTweet layers\n",
    "    else:\n",
    "        for layer_num in range(num_train_layers):\n",
    "            bertweet_model.roberta.encoder.layer[layer_num].trainable = False\n",
    "    \n",
    "    input_ids = tf.keras.layers.Input(shape=(max_sequence_length,), dtype=tf.int64, name='input_ids_layer')\n",
    "    token_type_ids = tf.keras.layers.Input(shape=(max_sequence_length,), dtype=tf.int64, name='token_type_ids_layer')\n",
    "    attention_mask = tf.keras.layers.Input(shape=(max_sequence_length,), dtype=tf.int64, name='attention_mask_layer')\n",
    "\n",
    "    bert_inputs = {'input_ids': input_ids,\n",
    "                   'token_type_ids': token_type_ids,\n",
    "                   'attention_mask': attention_mask}      \n",
    "\n",
    "    # Use the same bertweet model instance\n",
    "    bert_out = bertweet_model(bert_inputs)\n",
    "\n",
    "    cls_token = bert_out[0][:, 0, :]\n",
    "\n",
    "    \n",
    "    hidden = tf.keras.layers.Dense(hidden_size, activation='relu', name='hidden_layer')(cls_token)\n",
    "\n",
    "    hidden = tf.keras.layers.Dropout(dropout)(hidden)  \n",
    "\n",
    "    f1_score = tfa.metrics.F1Score(1, threshold = 0.5)\n",
    "\n",
    "    classification = tf.keras.layers.Dense(1, activation='sigmoid', name='classification_layer')(hidden)\n",
    "    \n",
    "    classification_model = tf.keras.Model(inputs=[input_ids, token_type_ids, attention_mask], outputs=[classification])\n",
    "    \n",
    "    classification_model.compile(optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=learning_rate),\n",
    "                                 loss=tf.keras.losses.BinaryCrossentropy(from_logits=False), \n",
    "                                 metrics=[tf.keras.metrics.BinaryAccuracy(),\n",
    "                                        tf.keras.metrics.Precision(),\n",
    "                                        tf.keras.metrics.Recall(),\n",
    "                                        f1_score])\n",
    "\n",
    "    return classification_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3390ff2",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "165a0f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_disability, y_train_disability, X_test_disability, y_test_disability, X_val_disability, y_val_disability = load_data('disability')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1513e398",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Doesn't work? How do we know? When the country is at the point of legalizing silencers, and the right of the mentally ill to own assault weapons, it's laughable to think we have ANY gun controls.\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_disability[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a6627800",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'LoL. The mental retardation of the (d)onkeys is stunning.\\nThey propose the craziest whackjob laws without one regard to the Constitution.'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_disability[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "91637bda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I can give examples of the peaceful Muslim missionaries murdering people 100 to 1 of your examples.  Islam is the religion of death.'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_disability[20]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c352de2f",
   "metadata": {},
   "source": [
    "## Load BERTweet Model from_pretrained() with normalization=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e252515b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1 Pro\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at vinai/bertweet-base were not used when initializing TFRobertaModel: ['lm_head']\n",
      "- This IS expected if you are initializing TFRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFRobertaModel were initialized from the model checkpoint at vinai/bertweet-base.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "# For transformers v4.x+:\n",
    "# bertweet_tokenizer = AutoTokenizer.from_pretrained(\"vinai/bertweet-base\", use_fast=False)\n",
    "# bertweet_tokenizer_heavy = AutoTokenizer.from_pretrained(\"vinai/bertweet-base\",\n",
    "#                                                     use_fast=False,\n",
    "#                                                     normalization=True,\n",
    "#                                                     add_special_tokens=True,\n",
    "#                                                     return_attention_mask=True)\n",
    "bertweet_tokenizer = AutoTokenizer.from_pretrained(\"vinai/bertweet-base\",\n",
    "                                                    use_fast=False,\n",
    "                                                    normalization=True,\n",
    "                                                    add_special_tokens=True,\n",
    "                                                    return_attention_mask=True)\n",
    "bertweet_model = TFRobertaModel.from_pretrained(\"vinai/bertweet-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fcc5ead2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['LoL',\n",
       " '.',\n",
       " 'The',\n",
       " 'mental',\n",
       " 'retar@@',\n",
       " 'dation',\n",
       " 'of',\n",
       " 'the',\n",
       " '(',\n",
       " 'd',\n",
       " ')',\n",
       " 'on@@',\n",
       " 'keys',\n",
       " 'is',\n",
       " 'stunning',\n",
       " '.',\n",
       " 'They',\n",
       " 'propose',\n",
       " 'the',\n",
       " 'craziest',\n",
       " 'wha@@',\n",
       " 'ck@@',\n",
       " 'job',\n",
       " 'laws',\n",
       " 'without',\n",
       " 'one',\n",
       " 'regard',\n",
       " 'to',\n",
       " 'the',\n",
       " 'Constitution',\n",
       " '.']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bertweet_tokenizer.tokenize(X_train_disability[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d89bd3a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bertweet_tokenizer_heavy.tokenize(X_train_disability[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "01854eb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"tf_roberta_model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " roberta (TFRobertaMainLayer  multiple                 134899968 \n",
      " )                                                               \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 134,899,968\n",
      "Trainable params: 134,899,968\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "bertweet_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bbf0d8f",
   "metadata": {},
   "source": [
    "## Tokenize Data Splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b25b6965",
   "metadata": {},
   "outputs": [],
   "source": [
    "bertweet_train_inputs_disability = tokenizing_pipeline(X_train_disability, bertweet_tokenizer)\n",
    "bertweet_test_inputs_disability = tokenizing_pipeline(X_test_disability, bertweet_tokenizer)\n",
    "bertweet_val_inputs_disability = tokenizing_pipeline(X_val_disability, bertweet_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9751de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X_train_disability)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e58f74c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X_val_disability)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac1e0a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X_test_disability)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94f5b97a",
   "metadata": {},
   "source": [
    "## Calculate Class Weights for Disability"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6f287eb",
   "metadata": {},
   "source": [
    "Get class weights for disability train set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c048779",
   "metadata": {},
   "outputs": [],
   "source": [
    "neg, pos = np.bincount(y_train_disability)\n",
    "total = neg + pos\n",
    "print('Disability Examples:\\n    Total: {}\\n    Positive: {} ({:.2f}% of total)\\n'.format(\n",
    "    total, pos, 100 * pos / total))\n",
    "\n",
    "# Scaling by total/2 helps keep the loss to a similar magnitude.\n",
    "# The sum of the weights of all examples stays the same.\n",
    "weight_for_0 = (1 / neg) * (total / 2.0)\n",
    "weight_for_1 = (1 / pos) * (total / 2.0)\n",
    "\n",
    "disability_class_weight = {0: weight_for_0, 1: weight_for_1}\n",
    "\n",
    "print('Disability Weight for class 0: {:.2f}'.format(weight_for_0))\n",
    "print('Disability Weight for class 1: {:.2f}'.format(weight_for_1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3129f17c",
   "metadata": {},
   "source": [
    "## Build Disability Model with half-frozen BERTweet layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b72fe4c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "disability_model = build_bertweet_cls_model(num_train_layers=6, learning_rate=1e-5)\n",
    "disability_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea9b921b",
   "metadata": {},
   "outputs": [],
   "source": [
    "america_la_tz = pytz.timezone('America/Los_Angeles')\n",
    "start_time = datetime.datetime.now(tz=america_la_tz).isoformat()\n",
    "print(str(start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4cda4e3",
   "metadata": {},
   "source": [
    "## Define Checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "febb3077",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_filepath = 'model_checkpoints/disability_only_best_weights.h5'\n",
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    verbose=1,\n",
    "    monitor='val_f1_score',\n",
    "    mode='max',\n",
    "    save_best_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4ed6610",
   "metadata": {},
   "source": [
    "## Train Disability Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14535c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "disability_history = disability_model.fit(bertweet_train_inputs_disability,\n",
    "                                          y_train_disability,\n",
    "                                          validation_data=(bertweet_val_inputs_disability, y_val_disability),\n",
    "#                                           batch_size=32,\n",
    "                                          batch_size=1024,\n",
    "#                                           epochs=5,\n",
    "                                          epochs=1,\n",
    "                                          class_weight=disability_class_weight,\n",
    "                                          callbacks=[model_checkpoint_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "347ff0c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = pd.DataFrame(disability_history.history)\n",
    "plt.ylabel('F1 Score')\n",
    "plt.xlabel('Epoch')\n",
    "plt.title('Disability Only Train vs Val F1 Score for Half-Frozen Bertweet')\n",
    "plt.xticks([0, 1, 2, 3, 4],['1', '2', '3', '4', '5'])\n",
    "plt.plot(history['f1_score'], label=\"training\", marker='o')\n",
    "plt.plot(history['val_f1_score'], label=\"validation\", marker='o')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab6607bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = pd.DataFrame(disability_history.history)\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.title('Disability Only Train vs Val Loss for Half-Frozen Bertweet')\n",
    "plt.xticks([0, 1, 2, 3, 4],['1', '2', '3', '4', '5'])\n",
    "plt.plot(history['loss'], label=\"training\", marker='o')\n",
    "plt.plot(history['val_loss'], label=\"validation\", marker='o')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad42b36b",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = pd.DataFrame(disability_history.history)\n",
    "plt.ylabel('F1 Score')\n",
    "plt.xlabel('Epoch')\n",
    "plt.title('Disability Only Train vs Val Binary Accuracy for Half-Frozen Bertweet')\n",
    "plt.xticks([0, 1, 2, 3, 4],['1', '2', '3', '4', '5'])\n",
    "plt.plot(history['binary_accuracy'], label=\"training\", marker='o')\n",
    "plt.plot(history['val_binary_accuracy'], label=\"validation\", marker='o')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e490f79f",
   "metadata": {},
   "outputs": [],
   "source": [
    "end_time = datetime.datetime.now(tz=america_la_tz).isoformat()\n",
    "print(str(end_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c4fb6da",
   "metadata": {},
   "source": [
    "## Evaluate Disability Model on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f97f561d",
   "metadata": {},
   "outputs": [],
   "source": [
    "disability_test_history = disability_model.evaluate(bertweet_test_inputs_disability, y_test_disability)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83d47671",
   "metadata": {},
   "source": [
    "## Export Results to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8be4d31e",
   "metadata": {},
   "outputs": [],
   "source": [
    "disability_test_history_df = pd.DataFrame({\n",
    "    'test_loss': disability_test_history[0],\n",
    "    'test_binary_accuracy': disability_test_history[1],\n",
    "    'test_precision': disability_test_history[2],\n",
    "    'test_recall': disability_test_history[3],\n",
    "    'test_f1_score': disability_test_history[4]})\n",
    "disability_results_df = pd.concat([pd.DataFrame(disability_history.history), disability_test_history_df], axis=0)\n",
    "disability_results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eb575fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "disability_results_df.to_csv('experiment_results/BERTweet_Disability_Only_take5.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3536ba90",
   "metadata": {},
   "source": [
    "# Save Model Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0c1e9aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "disability_model.save_weights('saved_weights/BERTweet_Disability_Only_take5.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a00f78c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "disability_model.save('saved_models/BERTweet_Disability_Only_take5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86c4b7b7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 (tensorflow)",
   "language": "python",
   "name": "w266tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
