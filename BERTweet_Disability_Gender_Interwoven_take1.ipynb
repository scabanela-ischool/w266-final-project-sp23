{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b290647f",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56d93d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "import transformers\n",
    "from transformers import AutoTokenizer,TFRobertaModel\n",
    "# from transformers import AutoTokenizer,AutoModel\n",
    "# from tensorflow.keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b08796d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detect hardware, return appropriate distribution strategy\n",
    "try:\n",
    "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
    "    print('Running on TPU ', tpu.master())\n",
    "except ValueError:\n",
    "    tpu = None\n",
    "\n",
    "if tpu:\n",
    "    tf.config.experimental_connect_to_cluster(tpu)\n",
    "    tf.tpu.experimental.initialize_tpu_system(tpu)\n",
    "    strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
    "else:\n",
    "    # Default distribution strategy in Tensorflow. Works on CPU and single GPU.\n",
    "    strategy = tf.distribute.get_strategy()\n",
    "\n",
    "print(\"REPLICAS: \", strategy.num_replicas_in_sync)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c618e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What version of Python do you have?\n",
    "import sys\n",
    "import platform\n",
    "import sklearn as sk\n",
    "\n",
    "print(f\"Python Platform: {platform.platform()}\")\n",
    "print(f\"Tensor Flow Version: {tf.__version__}\")\n",
    "print(f\"Keras Version: {tf.keras.__version__}\")\n",
    "print()\n",
    "print(f\"Python {sys.version}\")\n",
    "print(f\"Pandas {pd.__version__}\")\n",
    "print(f\"Scikit-Learn {sk.__version__}\")\n",
    "gpu = len(tf.config.list_physical_devices('GPU'))>0\n",
    "print(\"GPU is\", \"available\" if gpu else \"NOT AVAILABLE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc0f02d7",
   "metadata": {},
   "source": [
    "## Functions and Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd4f28c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_arrays(df):\n",
    "  X = df['comment_text'].to_numpy()\n",
    "  y = df['toxicity_binary'].to_numpy()\n",
    "  return X, y\n",
    "\n",
    "def load_data(group):\n",
    "  df_train = pd.read_csv('data/' + group + '-dataset-train.csv')\n",
    "  df_val = pd.read_csv('data/' + group + '-dataset-val.csv')\n",
    "  df_test = pd.read_csv('data/' + group + '-dataset-test.csv')\n",
    "\n",
    "  X_train, y_train = to_arrays(df_train)\n",
    "  X_val, y_val = to_arrays(df_val)\n",
    "  X_test, y_test = to_arrays(df_test)\n",
    "\n",
    "  return X_train, y_train, X_test, y_test, X_val, y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9337eb1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_SEQUENCE_LENGTH = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fad87a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenizing_pipeline(X, tokenizer):\n",
    "  bert_tokenized = tokenizer(list(X),\n",
    "                max_length=MAX_SEQUENCE_LENGTH,\n",
    "                truncation=True,\n",
    "                padding='max_length',\n",
    "                return_tensors='tf')\n",
    "  bert_inputs = [bert_tokenized.input_ids,\n",
    "                 bert_tokenized.token_type_ids,\n",
    "                 bert_tokenized.attention_mask]\n",
    "  return bert_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a21a4ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_bertweet_cls_model(max_sequence_length=MAX_SEQUENCE_LENGTH,\n",
    "                          hidden_size=100, \n",
    "                          dropout=0.3,\n",
    "                          learning_rate=0.0001,\n",
    "                          num_train_layers=0):\n",
    "\n",
    "    # freeze all pre-trained BERTweet layers\n",
    "    if num_train_layers == 0:\n",
    "      bertweet_model.trainable = False\n",
    "    \n",
    "    # partially freeze pre-trained BERTweet layers\n",
    "    else:\n",
    "      retrain_layers = []\n",
    "\n",
    "      for layer_num in range(num_train_layers):\n",
    "          layer_code = '_' + str(11 - layer_num)\n",
    "          retrain_layers.append(layer_code)\n",
    "        \n",
    "      for w in bert_model.weights:\n",
    "          if not any([x in w.name for x in retrain_layers]):\n",
    "              w._trainable = False\n",
    "    \n",
    "    input_ids = tf.keras.layers.Input(shape=(max_sequence_length,), dtype=tf.int64, name='input_ids_layer')\n",
    "    token_type_ids = tf.keras.layers.Input(shape=(max_sequence_length,), dtype=tf.int64, name='token_type_ids_layer')\n",
    "    attention_mask = tf.keras.layers.Input(shape=(max_sequence_length,), dtype=tf.int64, name='attention_mask_layer')\n",
    "\n",
    "    bert_inputs = {'input_ids': input_ids,\n",
    "                   'token_type_ids': token_type_ids,\n",
    "                   'attention_mask': attention_mask}      \n",
    "\n",
    "    # Use the same bertweet model instance\n",
    "    bert_out = bertweet_model(bert_inputs)\n",
    "\n",
    "    cls_token = bert_out[0][:, 0, :]\n",
    "\n",
    "    \n",
    "    hidden = tf.keras.layers.Dense(hidden_size, activation='relu', name='hidden_layer')(cls_token)\n",
    "\n",
    "    hidden = tf.keras.layers.Dropout(dropout)(hidden)  \n",
    "\n",
    "    f1_score = tfa.metrics.F1Score(1, threshold = 0.5)\n",
    "\n",
    "    classification = tf.keras.layers.Dense(1, activation='sigmoid', name='classification_layer')(hidden)\n",
    "    \n",
    "    classification_model = tf.keras.Model(inputs=[input_ids, token_type_ids, attention_mask], outputs=[classification])\n",
    "    \n",
    "    classification_model.compile(optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=learning_rate),\n",
    "                                 loss=tf.keras.losses.BinaryCrossentropy(from_logits=False), \n",
    "                                 metrics=[tf.keras.metrics.BinaryAccuracy(),\n",
    "                                        tf.keras.metrics.Precision(),\n",
    "                                        tf.keras.metrics.Recall(),\n",
    "                                        f1_score])\n",
    "\n",
    "    return classification_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3cd887f",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48d66f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_disability, y_train_disability, X_test_disability, y_test_disability, X_val_disability, y_val_disability = load_data('disability')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24968032",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train_disability[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0a5c815",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_disability[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "625196bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_gender, y_train_gender, X_test_gender, y_test_gender, X_val_gender, y_val_gender = load_data('gender')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc30b670",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_gender[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c31ad866",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_gender[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89f756e7",
   "metadata": {},
   "source": [
    "## Load BERTweet Model from_pretrained()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54f86b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For transformers v4.x+:\n",
    "bertweet_tokenizer = AutoTokenizer.from_pretrained(\"vinai/bertweet-base\", use_fast=False)\n",
    "bertweet_model = TFRobertaModel.from_pretrained(\"vinai/bertweet-base\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a87bcf39",
   "metadata": {},
   "source": [
    "### Tokenize Data Splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "491248ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "bertweet_train_inputs_disability = tokenizing_pipeline(X_train_disability, bertweet_tokenizer)\n",
    "bertweet_test_inputs_disability = tokenizing_pipeline(X_test_disability, bertweet_tokenizer)\n",
    "bertweet_val_inputs_disability = tokenizing_pipeline(X_val_disability, bertweet_tokenizer)\n",
    "\n",
    "bertweet_train_inputs_gender = tokenizing_pipeline(X_train_gender, bertweet_tokenizer)\n",
    "bertweet_test_inputs_gender = tokenizing_pipeline(X_test_gender, bertweet_tokenizer)\n",
    "bertweet_val_inputs_gender = tokenizing_pipeline(X_val_gender, bertweet_tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f60836d",
   "metadata": {},
   "source": [
    "# Calculate Class Weights for Each Identity Group"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bf71e2f",
   "metadata": {},
   "source": [
    "Get class weights for disability train set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e9e8161",
   "metadata": {},
   "outputs": [],
   "source": [
    "neg, pos = np.bincount(y_train_disability)\n",
    "total = neg + pos\n",
    "print('Disability Examples:\\n    Total: {}\\n    Positive: {} ({:.2f}% of total)\\n'.format(\n",
    "    total, pos, 100 * pos / total))\n",
    "\n",
    "# Scaling by total/2 helps keep the loss to a similar magnitude.\n",
    "# The sum of the weights of all examples stays the same.\n",
    "weight_for_0 = (1 / neg) * (total / 2.0)\n",
    "weight_for_1 = (1 / pos) * (total / 2.0)\n",
    "\n",
    "disability_class_weight = {0: weight_for_0, 1: weight_for_1}\n",
    "\n",
    "print('Disability Weight for class 0: {:.2f}'.format(weight_for_0))\n",
    "print('Disability Weight for class 1: {:.2f}'.format(weight_for_1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e82252c3",
   "metadata": {},
   "source": [
    "Get class weights for gender train set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cddedca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "neg, pos = np.bincount(y_train_gender)\n",
    "total = neg + pos\n",
    "print('Gender Examples:\\n    Total: {}\\n    Positive: {} ({:.2f}% of total)\\n'.format(\n",
    "    total, pos, 100 * pos / total))\n",
    "\n",
    "# Scaling by total/2 helps keep the loss to a similar magnitude.\n",
    "# The sum of the weights of all examples stays the same.\n",
    "weight_for_0 = (1 / neg) * (total / 2.0)\n",
    "weight_for_1 = (1 / pos) * (total / 2.0)\n",
    "\n",
    "gender_class_weight = {0: weight_for_0, 1: weight_for_1}\n",
    "\n",
    "print('Gender Weight for class 0: {:.2f}'.format(weight_for_0))\n",
    "print('Gender Weight for class 1: {:.2f}'.format(weight_for_1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33235d0a",
   "metadata": {},
   "source": [
    "# Build Disability Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc671424",
   "metadata": {},
   "outputs": [],
   "source": [
    "disability_model = build_bertweet_cls_model(num_train_layers=6, learning_rate=0.0001)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e50baaeb",
   "metadata": {},
   "source": [
    "# Build Gender Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0340a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "gender_model = build_bertweet_cls_model(num_train_layers=6, learning_rate=1e-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e4690c7",
   "metadata": {},
   "source": [
    "# Round 1: Train Disability Model for 3 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f35772fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "disability_round1_history = disability_model.fit(bert_train_inputs_disability,\n",
    "                                          y_train_disability,\n",
    "                                          validation_data=(bert_val_inputs_disability, y_val_disability),\n",
    "                                          batch_size=64,\n",
    "                                          epochs=3,\n",
    "                                          class_weight=disability_class_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67fa12ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = pd.DataFrame(disability_round1_history.history)\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.title('Round 1: Disability Train vs Val Loss for Half-Frozen Bertweet')\n",
    "plt.xticks(range(0, len(history['loss'] + 1)))\n",
    "plt.plot(history['loss'], label=\"training\", marker='o')\n",
    "plt.plot(history['val_loss'], label=\"validation\", marker='o')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66cdfd7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = pd.DataFrame(disability_round1_history.history)\n",
    "plt.ylabel('F1 Score')\n",
    "plt.xlabel('Epoch')\n",
    "plt.title('Round 1: Disability Train vs Val F1 Score for Half-Frozen Bertweet')\n",
    "plt.xticks(range(0, len(history['f1_score'] + 1)))\n",
    "plt.plot(history['f1_score'], label=\"training\", marker='o')\n",
    "plt.plot(history['val_f1_score'], label=\"validation\", marker='o')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f133cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = pd.DataFrame(disability_round1_history.history)\n",
    "plt.ylabel('Binary Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.title('Round 1: Disability Train vs Val Binary Accuracy for Half-Frozen Bertweet')\n",
    "plt.xticks(range(0, len(history['binary_accuracy'] + 1)))\n",
    "plt.plot(history['binary_accuracy'], label=\"training\", marker='o')\n",
    "plt.plot(history['val_binary_accuracy'], label=\"validation\", marker='o')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3eeac13",
   "metadata": {},
   "source": [
    "### Change learning rate for disability_model to something much smaller for future training steps and recompile:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "079fe693",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score = tfa.metrics.F1Score(1, threshold = 0.5)\n",
    "disability_model.compile(optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=1e-5),\n",
    "                                 loss=tf.keras.losses.BinaryCrossentropy(from_logits=False), \n",
    "                                 metrics=[tf.keras.metrics.BinaryAccuracy(),\n",
    "                                        tf.keras.metrics.Precision(),\n",
    "                                        tf.keras.metrics.Recall(),\n",
    "                                        f1_score])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb0ddb48",
   "metadata": {},
   "source": [
    "# Round 2: Train Gender Model for 1 epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d65a2550",
   "metadata": {},
   "outputs": [],
   "source": [
    "gender_round2_history = gender_model.fit(bert_train_inputs_gender,\n",
    "                                          y_train_gender,\n",
    "                                          validation_data=(bert_val_inputs_gender, y_val_gender),\n",
    "                                          batch_size=32,\n",
    "                                          epochs=1,\n",
    "                                          class_weight=gender_class_weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d5d9dfd",
   "metadata": {},
   "source": [
    "# Round 3: Train Disability Model for 1 epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30ed25ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "disability_round3_history = disability_model.fit(bert_train_inputs_disability,\n",
    "                                          y_train_disability,\n",
    "                                          validation_data=(bert_val_inputs_disability, y_val_disability),\n",
    "                                          batch_size=32,\n",
    "                                          epochs=1,\n",
    "                                          class_weight=disability_class_weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5b5a829",
   "metadata": {},
   "source": [
    "# Round 4: Train Gender Model for 1 epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc63944c",
   "metadata": {},
   "outputs": [],
   "source": [
    "gender_round4_history = gender_model.fit(bert_train_inputs_gender,\n",
    "                                          y_train_gender,\n",
    "                                          validation_data=(bert_val_inputs_gender, y_val_gender),\n",
    "                                          batch_size=32,\n",
    "                                          epochs=1,\n",
    "                                          class_weight=gender_class_weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "393a96e6",
   "metadata": {},
   "source": [
    "# Round 4: Train Disability Model for 1 epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e5b1d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "disability_round4_history = disability_model.fit(bert_train_inputs_disability,\n",
    "                                          y_train_disability,\n",
    "                                          validation_data=(bert_val_inputs_disability, y_val_disability),\n",
    "                                          batch_size=32,\n",
    "                                          epochs=1,\n",
    "                                          class_weight=disability_class_weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4105078f",
   "metadata": {},
   "source": [
    "# Round 5: Train Gender Model for 1 epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ba3c3bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "gender_round5_history = gender_model.fit(bert_train_inputs_gender,\n",
    "                                          y_train_gender,\n",
    "                                          validation_data=(bert_val_inputs_gender, y_val_gender),\n",
    "                                          batch_size=32,\n",
    "                                          epochs=1,\n",
    "                                          class_weight=gender_class_weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba5105e7",
   "metadata": {},
   "source": [
    "# Round 6: Train Disability Model for 1 epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4a9a9a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "disability_round6_history = disability_model.fit(bert_train_inputs_disability,\n",
    "                                          y_train_disability,\n",
    "                                          validation_data=(bert_val_inputs_disability, y_val_disability),\n",
    "                                          batch_size=32,\n",
    "                                          epochs=1,\n",
    "                                          class_weight=disability_class_weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cec0257",
   "metadata": {},
   "source": [
    "# Evaluate disability_model on Disability Test Set (MAIN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b0d8e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "disability_model.evaluate(bertweet_test_inputs_disability, y_test_disability)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ec0abf2",
   "metadata": {},
   "source": [
    "# Evaluate gender_model on Gender Test Set (supporting)\n",
    "To see if gender is easier to predict than disability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8c4544b",
   "metadata": {},
   "outputs": [],
   "source": [
    "gender_model.evaluate(bertweet_test_inputs_gender, y_test_gender)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72fafe2b",
   "metadata": {},
   "source": [
    "# Save Model Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d342205f",
   "metadata": {},
   "outputs": [],
   "source": [
    "disability_model.save_weights('saved_models/disability_interwoven_half_frozen_weights.h5')\n",
    "gender_model.save_weights('saved_models/gender_interwoven_half_frozen_weights.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 (tensorflow)",
   "language": "python",
   "name": "w266tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
